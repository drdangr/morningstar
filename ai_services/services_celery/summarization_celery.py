#!/usr/bin/env python3
"""
SummarizationServiceCelery - Celery-–∞–¥–∞–ø—Ç–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è AI —Å–∞–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏
–°–∫–æ–ø–∏—Ä–æ–≤–∞–Ω–æ –∏–∑ services/summarization.py –∏ –∞–¥–∞–ø—Ç–∏—Ä–æ–≤–∞–Ω–æ –¥–ª—è —Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–π —Ä–∞–±–æ—Ç—ã –≤ Celery
–£—á–∏—Ç—ã–≤–∞–µ—Ç –ø—Ä–æ–±–ª–µ–º—ã —Å –±–∞—Ç—á–µ–≤–æ–π —Å–∞–º–º–∞—Ä–∏–∑–∞—Ü–∏–µ–π - –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –æ–¥–∏–Ω–æ—á–Ω—ã–π –∏ –±–∞—Ç—á–µ–≤—ã–π —Ä–µ–∂–∏–º—ã
"""

import json
import re
import time
import logging
import os
from typing import Dict, List, Optional, Any
from openai import OpenAI
from .base_celery import BaseAIServiceCelery

logger = logging.getLogger(__name__)

class SummarizationServiceCelery(BaseAIServiceCelery):
    """
    –°–µ—Ä–≤–∏—Å –¥–ª—è AI-—Å–∞–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏ –ø–æ—Å—Ç–æ–≤ –≤ Celery
    –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –æ–¥–∏–Ω–æ—á–Ω—ã–π —Ä–µ–∂–∏–º (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è) –∏ –±–∞—Ç—á–µ–≤—ã–π —Ä–µ–∂–∏–º
    """
    
    def __init__(self, model_name: str = "gpt-4", max_tokens: int = 4000, temperature: float = 0.3,
                 max_summary_length: int = 150, settings_manager=None):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–µ—Ä–≤–∏—Å–∞
        
        Args:
            model_name: –ú–æ–¥–µ–ª—å OpenAI –¥–ª—è —Å–∞–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏
            max_tokens: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–∫–µ–Ω–æ–≤
            temperature: –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
            max_summary_length: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ summary
            settings_manager: –ú–µ–Ω–µ–¥–∂–µ—Ä –Ω–∞—Å—Ç—Ä–æ–µ–∫ –¥–ª—è –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏—Ö LLM
        """
        super().__init__(settings_manager)
        
        self.model_name = model_name
        self.max_tokens = max_tokens
        self.temperature = temperature
        self.max_summary_length = max_summary_length
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º OpenAI –∫–ª–∏–µ–Ω—Ç (—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π)
        api_key = self._get_openai_key()
        self.client = OpenAI(api_key=api_key)
        
        logger.info(f"üìù SummarizationServiceCelery –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
        logger.info(f"   –ú–æ–¥–µ–ª—å: {model_name}")
        logger.info(f"   Max tokens: {max_tokens}")
        logger.info(f"   Temperature: {temperature}")
        logger.info(f"   Max summary length: {max_summary_length}")
        if settings_manager:
            logger.info(f"   SettingsManager: –ø–æ–¥–∫–ª—é—á–µ–Ω")
        else:
            logger.warning(f"   ‚ö†Ô∏è SettingsManager –Ω–µ –ø–æ–¥–∫–ª—é—á–µ–Ω")
    
    def process(self, text: str, language: str = "ru", custom_prompt: Optional[str] = None, 
                max_summary_length: Optional[int] = None, **kwargs) -> Dict[str, Any]:
        """
        –°–æ–∑–¥–∞–Ω–∏–µ –∫—Ä–∞—Ç–∫–æ–≥–æ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—è –æ–¥–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞
        
        Args:
            text: –¢–µ–∫—Å—Ç –¥–ª—è —Å–∞–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏
            language: –Ø–∑—ã–∫ —Ç–µ–∫—Å—Ç–∞
            custom_prompt: –ö–∞—Å—Ç–æ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç
            max_summary_length: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ summary
            **kwargs: –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
            
        Returns:
            –†–µ–∑—É–ª—å—Ç–∞—Ç —Å–∞–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏
        """
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤–∞–ª–∏–¥–Ω–æ—Å—Ç—å –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
            if not text or not text.strip():
                return {
                    "summary": "",
                    "status": "skipped",
                    "reason": "empty_text"
                }
            
            # –ü–æ–ª—É—á–∞–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∏–∑ SettingsManager –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ–º –¥–µ—Ñ–æ–ª—Ç–Ω—ã–µ
            model, max_tokens, temperature, top_p = self._get_model_settings()
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º –ø—Ä–æ–º–ø—Ç
            summary_length = max_summary_length or self.max_summary_length
            prompt = self._build_single_prompt(custom_prompt, language, summary_length)
            
            # –í—ã–∑—ã–≤–∞–µ–º OpenAI API
            response = self.client.chat.completions.create(
                model=model,
                messages=[
                    {"role": "system", "content": prompt},
                    {"role": "user", "content": text}
                ],
                max_tokens=max_tokens,
                temperature=temperature,
                top_p=top_p
            )
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            summary = response.choices[0].message.content.strip()
            
            return {
                "summary": summary,
                "language": language,
                "tokens_used": response.usage.total_tokens,
                "status": "success"
            }
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ process: {e}")
            return {
                "summary": f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {str(e)}",
                "status": "error",
                "error": str(e)
            }
    
    def process_batch(self, texts: List[str], language: str = "ru", custom_prompt: Optional[str] = None,
                     max_summary_length: Optional[int] = None, **kwargs) -> List[Dict[str, Any]]:
        """
        –ë–∞—Ç—á–µ–≤–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–æ–≤ –æ–¥–Ω–∏–º –∑–∞–ø—Ä–æ—Å–æ–º
        
        –í–ù–ò–ú–ê–ù–ò–ï: –ë–∞—Ç—á–µ–≤–∞—è —Å–∞–º–º–∞—Ä–∏–∑–∞—Ü–∏—è –º–æ–∂–µ—Ç –¥–∞–≤–∞—Ç—å –Ω–µ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã!
        –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –æ–¥–∏–Ω–æ—á–Ω—ã–π —Ä–µ–∂–∏–º –∏–ª–∏ OpenAI Batch API
        
        Args:
            texts: –°–ø–∏—Å–æ–∫ —Ç–µ–∫—Å—Ç–æ–≤ –¥–ª—è —Å–∞–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏
            language: –Ø–∑—ã–∫ —Ç–µ–∫—Å—Ç–æ–≤
            custom_prompt: –ö–∞—Å—Ç–æ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç
            max_summary_length: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ summary
            **kwargs: –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
            
        Returns:
            –°–ø–∏—Å–æ–∫ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Å–∞–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏
        """
        
        if not texts:
            return []
        
        logger.info(f"üöÄ –ë–∞—Ç—á–µ–≤–∞—è —Å–∞–º–º–∞—Ä–∏–∑–∞—Ü–∏—è {len(texts)} —Ç–µ–∫—Å—Ç–æ–≤")
        logger.warning(f"‚ö†Ô∏è –ë–∞—Ç—á–µ–≤–∞—è —Å–∞–º–º–∞—Ä–∏–∑–∞—Ü–∏—è –º–æ–∂–µ—Ç –¥–∞–≤–∞—Ç—å –Ω–µ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã!")
        
        try:
            # –ü–æ–ª—É—á–∞–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
            model, max_tokens, temperature, top_p = self._get_model_settings()
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º –±–∞—Ç—á–µ–≤—ã–π –ø—Ä–æ–º–ø—Ç
            summary_length = max_summary_length or self.max_summary_length
            batch_prompt = self._build_batch_prompt(texts, custom_prompt, language, summary_length)
            
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å –∫ OpenAI
            response = self.client.chat.completions.create(
                model=model,
                messages=[
                    {"role": "user", "content": batch_prompt}
                ],
                max_tokens=max_tokens * 2,  # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –¥–ª—è –±–∞—Ç—á–∞
                temperature=temperature,
                top_p=top_p
            )
            
            # –ü–∞—Ä—Å–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            response_text = response.choices[0].message.content.strip()
            summaries = self._parse_batch_response(response_text, len(texts))
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            total_tokens = response.usage.total_tokens
            tokens_per_text = total_tokens // len(texts) if texts else 0
            
            results = []
            for i, summary in enumerate(summaries):
                results.append({
                    "summary": summary,
                    "language": language,
                    "tokens_used": tokens_per_text,
                    "status": "success"
                })
            
            logger.info(f"‚úÖ –ë–∞—Ç—á–µ–≤–∞—è —Å–∞–º–º–∞—Ä–∏–∑–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞: {len(results)} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
            return results
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –±–∞—Ç—á–µ–≤–æ–π —Å–∞–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏: {e}")
            
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—à–∏–±–∫–∏ –¥–ª—è –≤—Å–µ—Ö —Ç–µ–∫—Å—Ç–æ–≤
            return [{
                "summary": f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–µ–∫—Å—Ç–∞ {i+1}",
                "language": language,
                "tokens_used": 0,
                "status": "error",
                "error": str(e)
            } for i in range(len(texts))]
    
    def process_posts_individually(self, posts: List[Dict], language: str = "ru", 
                                  custom_prompt: Optional[str] = None, **kwargs) -> List[Dict[str, Any]]:
        """
        –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –ø–æ—Å—Ç—ã –ø–æ –æ–¥–Ω–æ–º—É (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–π —Ä–µ–∂–∏–º)
        
        Args:
            posts: –°–ø–∏—Å–æ–∫ –ø–æ—Å—Ç–æ–≤ –¥–ª—è —Å–∞–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏
            language: –Ø–∑—ã–∫ —Ç–µ–∫—Å—Ç–æ–≤
            custom_prompt: –ö–∞—Å—Ç–æ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç
            **kwargs: –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
            
        Returns:
            –°–ø–∏—Å–æ–∫ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Å–∞–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏
        """
        logger.info(f"üìù –ò–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω–∞—è —Å–∞–º–º–∞—Ä–∏–∑–∞—Ü–∏—è {len(posts)} –ø–æ—Å—Ç–æ–≤")
        
        results = []
        for i, post in enumerate(posts, 1):
            try:
                # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç –ø–æ—Å—Ç–∞
                text = post.get('text', '')
                if not text or not text.strip():
                    results.append({
                        "post_id": post.get('id'),
                        "summary": "",
                        "status": "skipped",
                        "reason": "empty_text"
                    })
                    continue
                
                # –°–∞–º–º–∞—Ä–∏–∑—É–µ–º –ø–æ—Å—Ç
                result = self.process(text, language, custom_prompt, **kwargs)
                
                # –î–æ–±–∞–≤–ª—è–µ–º ID –ø–æ—Å—Ç–∞ –∫ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—É
                result['post_id'] = post.get('id')
                results.append(result)
                
                logger.info(f"‚úÖ –ü–æ—Å—Ç {i}/{len(posts)} –æ–±—Ä–∞–±–æ—Ç–∞–Ω")
                
            except Exception as e:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ø–æ—Å—Ç–∞ {i}: {e}")
                results.append({
                    "post_id": post.get('id'),
                    "summary": f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {str(e)}",
                    "status": "error",
                    "error": str(e)
                })
        
        logger.info(f"‚úÖ –ò–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω–∞—è —Å–∞–º–º–∞—Ä–∏–∑–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞: {len(results)} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
        return results
    
    def _get_model_settings(self) -> tuple:
        """–ü–æ–ª—É—á–∞–µ—Ç –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –º–æ–¥–µ–ª–∏ –∏–∑ SettingsManager –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –¥–µ—Ñ–æ–ª—Ç–Ω—ã–µ"""
        if self.settings_manager:
            try:
                config = self.settings_manager.get_ai_service_config('summarization')
                return (
                    config.get('model', self.model_name),
                    config.get('max_tokens', self.max_tokens),
                    config.get('temperature', self.temperature),
                    config.get('top_p', 1.0)
                )
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –Ω–∞—Å—Ç—Ä–æ–µ–∫: {e}")
        
        # –î–µ—Ñ–æ–ª—Ç–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
        return (
            self.model_name,
            self.max_tokens,
            self.temperature,
            1.0
        )
    
    def _build_single_prompt(self, custom_prompt: Optional[str], language: str, max_length: int) -> str:
        """–°—Ç—Ä–æ–∏—Ç –ø—Ä–æ–º–ø—Ç –¥–ª—è –æ–¥–∏–Ω–æ—á–Ω–æ–π —Å–∞–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏"""
        # –ë–∞–∑–æ–≤—ã–π –ø—Ä–æ–º–ø—Ç –∏–ª–∏ –∫–∞—Å—Ç–æ–º–Ω—ã–π
        base_prompt = custom_prompt or self._get_default_prompt(language)
        
        # –î–æ–±–∞–≤–ª—è–µ–º –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –ø–æ –¥–ª–∏–Ω–µ
        if max_length:
            length_instruction = f"\n\n–õ–∏–º–∏—Ç –¥–ª–∏–Ω—ã: –ø–æ—Å—Ç–∞—Ä–∞–π—Å—è —É–ª–æ–∂–∏—Ç—å—Å—è –ø—Ä–∏–º–µ—Ä–Ω–æ –≤ {max_length} —Å–∏–º–≤–æ–ª–æ–≤, –Ω–æ –Ω–µ –∂–µ—Ä—Ç–≤—É–π –≤–∞–∂–Ω—ã–º–∏ —á–∞—Å—Ç—è–º–∏ —Ä–∞–¥–∏ —ç—Ç–æ–≥–æ. –õ—É—á—à–µ —Å–ª–µ–≥–∫–∞ –ø—Ä–µ–≤—ã—Å–∏—Ç—å –ª–∏–º–∏—Ç, —á–µ–º –ø–æ—Ç–µ—Ä—è—Ç—å —Å—É—Ç—å –∏–ª–∏ –≤–∫—É—Å —Ç–µ–∫—Å—Ç–∞."
            return f"{base_prompt}{length_instruction}"
        
        return base_prompt
    
    def _build_batch_prompt(self, texts: List[str], custom_prompt: Optional[str], language: str, max_length: int) -> str:
        """–°—Ç—Ä–æ–∏—Ç –ø—Ä–æ–º–ø—Ç –¥–ª—è –±–∞—Ç—á–µ–≤–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏"""
        # –ù–∞—á–∏–Ω–∞–µ–º —Å –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –æ —Ñ–æ—Ä–º–∞—Ç–µ
        prompt = f"""–û–±—Ä–∞–±–æ—Ç–∞–π —Å–ª–µ–¥—É—é—â–∏–µ {len(texts)} —Ç–µ–∫—Å—Ç–æ–≤ –°–¢–†–û–ì–û –ü–†–ò–î–ï–†–ñ–ò–í–ê–Ø–°–¨ –î–õ–Ø –ö–ê–ñ–î–û–ì–û –ò–ó –¢–ï–ö–°–¢–û–í –ò–ù–°–¢–†–£–ö–¶–ò–ò –ù–ò–ñ–ï –∏ –≤–µ—Ä–Ω–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON –º–∞—Å—Å–∏–≤–∞.
–ö–∞–∂–¥—ã–π —ç–ª–µ–º–µ–Ω—Ç –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å –ø–æ–ª–µ "summary".

–§–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞:
[
  {{"summary": "—Ä–µ–∑—É–ª—å—Ç–∞—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–µ–∫—Å—Ç–∞ 1"}},
  {{"summary": "—Ä–µ–∑—É–ª—å—Ç–∞—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–µ–∫—Å—Ç–∞ 2"}},
  ...
]

–ò–ù–°–¢–†–£–ö–¶–ò–Ø –î–õ–Ø –ö–ê–ñ–î–û–ì–û –¢–ï–ö–°–¢–ê:
{custom_prompt or self._get_default_prompt(language)}

–õ–∏–º–∏—Ç –¥–ª–∏–Ω—ã summary: –ø—Ä–∏–º–µ—Ä–Ω–æ {max_length} —Å–∏–º–≤–æ–ª–æ–≤ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ.

–¢–ï–ö–°–¢–´ –î–õ–Ø –û–ë–†–ê–ë–û–¢–ö–ò:
"""
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Ç–µ–∫—Å—Ç—ã —Å –Ω–æ–º–µ—Ä–∞–º–∏
        for i, text in enumerate(texts, 1):
            prompt += f"\n\n=== –¢–ï–ö–°–¢ {i} ===\n{text}"
        
        return prompt
    
    def _parse_batch_response(self, response_text: str, expected_count: int) -> List[str]:
        """–ü–∞—Ä—Å–∏—Ç –±–∞—Ç—á–µ–≤—ã–π –æ—Ç–≤–µ—Ç –æ—Ç OpenAI"""
        summaries = []
        
        try:
            # –ü—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ JSON –≤ –æ—Ç–≤–µ—Ç–µ
            json_text = self._extract_json(response_text)
            if json_text:
                # –ü–∞—Ä—Å–∏–º JSON
                parsed = json.loads(json_text)
                
                # –ò–∑–≤–ª–µ–∫–∞–µ–º summary –∏–∑ –∫–∞–∂–¥–æ–≥–æ —ç–ª–µ–º–µ–Ω—Ç–∞
                if isinstance(parsed, list):
                    for item in parsed:
                        if isinstance(item, dict) and 'summary' in item:
                            summaries.append(item['summary'])
                        elif isinstance(item, str):
                            summaries.append(item)
                
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –±–∞—Ç—á–µ–≤–æ–≥–æ –æ—Ç–≤–µ—Ç–∞: {e}")
        
        # –î–æ–ø–æ–ª–Ω—è–µ–º –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏–µ summary
        while len(summaries) < expected_count:
            summaries.append(f"–ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å —Ç–µ–∫—Å—Ç {len(summaries) + 1}")
        
        # –û–±—Ä–µ–∑–∞–µ–º –ª–∏—à–Ω–∏–µ
        return summaries[:expected_count]
    
    def _extract_json(self, text: str) -> str:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç JSON –∏–∑ —Ç–µ–∫—Å—Ç–∞"""
        try:
            # –ò—â–µ–º –º–∞—Å—Å–∏–≤ JSON
            start = text.find('[')
            if start == -1:
                return ""
            
            # –ù–∞—Ö–æ–¥–∏–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â—É—é –∑–∞–∫—Ä—ã–≤–∞—é—â—É—é —Å–∫–æ–±–∫—É
            bracket_count = 0
            for i in range(start, len(text)):
                if text[i] == '[':
                    bracket_count += 1
                elif text[i] == ']':
                    bracket_count -= 1
                    if bracket_count == 0:
                        return text[start:i+1]
            
            return ""
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è JSON: {e}")
            return ""
    
    def _get_default_prompt(self, language: str) -> str:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –¥–µ—Ñ–æ–ª—Ç–Ω—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è —Å–∞–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏"""
        if language == "ru":
            return """–°–æ–∑–¥–∞–π –∫—Ä–∞—Ç–∫–æ–µ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞, —Å–æ—Ö—Ä–∞–Ω–∏–≤ –æ—Å–Ω–æ–≤–Ω—É—é –∏–¥–µ—é –∏ –∫–ª—é—á–µ–≤—ã–µ –¥–µ—Ç–∞–ª–∏.
–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è:
- –ü–∏—à–∏ –∫—Ä–∞—Ç–∫–æ, –Ω–æ –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω–æ
- –°–æ—Ö—Ä–∞–Ω—è–π –≥–ª–∞–≤–Ω—É—é –º—ã—Å–ª—å –∏ –≤–∞–∂–Ω—ã–µ —Ñ–∞–∫—Ç—ã
- –ò—Å–ø–æ–ª—å–∑—É–π –ø—Ä–æ—Å—Ç–æ–π –∏ –ø–æ–Ω—è—Ç–Ω—ã–π —è–∑—ã–∫
- –ù–µ –¥–æ–±–∞–≤–ª—è–π —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã–µ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ –∏–ª–∏ –æ—Ü–µ–Ω–∫–∏
- –ï—Å–ª–∏ –≤ —Ç–µ–∫—Å—Ç–µ –µ—Å—Ç—å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Ü–∏—Ñ—Ä—ã, –¥–∞—Ç—ã –∏–ª–∏ –∏–º–µ–Ω–∞ - –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –≤–∫–ª—é—á–∞–π –∏—Ö"""
        else:
            return """Create a concise summary of the text, preserving the main idea and key details.
Requirements:
- Write concisely but informatively
- Preserve the main idea and important facts
- Use simple and clear language
- Don't add your own comments or evaluations
- If the text contains specific numbers, dates, or names - be sure to include them"""
    
    def _get_openai_key(self) -> str:
        """–ü–æ–ª—É—á–∞–µ—Ç OpenAI API –∫–ª—é—á –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è"""
        api_key = os.getenv('OPENAI_API_KEY')
        if not api_key:
            raise ValueError("OPENAI_API_KEY environment variable is required") 