#!/usr/bin/env python3
"""
SummarizationServiceCelery - Celery-–∞–¥–∞–ø—Ç–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è AI —Å–∞–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏
–°–∫–æ–ø–∏—Ä–æ–≤–∞–Ω–æ –∏–∑ services/summarization.py –∏ –∞–¥–∞–ø—Ç–∏—Ä–æ–≤–∞–Ω–æ –¥–ª—è —Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–π —Ä–∞–±–æ—Ç—ã –≤ Celery
–£—á–∏—Ç—ã–≤–∞–µ—Ç –ø—Ä–æ–±–ª–µ–º—ã —Å –±–∞—Ç—á–µ–≤–æ–π —Å–∞–º–º–∞—Ä–∏–∑–∞—Ü–∏–µ–π - –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –æ–¥–∏–Ω–æ—á–Ω—ã–π –∏ –±–∞—Ç—á–µ–≤—ã–π —Ä–µ–∂–∏–º—ã
"""

import json
import re
import time
import logging
import os
import asyncio
from typing import Dict, List, Optional, Any
from openai import OpenAI
from .base_celery import BaseAIServiceCelery

# ‚ú® –ù–û–í–û–ï: –ò–º–ø–æ—Ä—Ç –µ–¥–∏–Ω–æ–π —Å—Ö–µ–º—ã –¥–∞–Ω–Ω—ã—Ö
import sys
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(__file__))))
from schemas import PostForSummarization, ProcessingStatus, ServiceResult

logger = logging.getLogger(__name__)

# üîß –ö–û–ù–¢–†–û–õ–¨ CONCURRENCY: –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã –∫ OpenAI  
OPENAI_SEMAPHORE = asyncio.Semaphore(2)  # –ú–∞–∫—Å–∏–º—É–º 2 –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–∞


class SummarizationServiceCelery(BaseAIServiceCelery):
    """
    –°–µ—Ä–≤–∏—Å –¥–ª—è AI-—Å–∞–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏ –ø–æ—Å—Ç–æ–≤ –≤ Celery
    –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –æ–¥–∏–Ω–æ—á–Ω—ã–π —Ä–µ–∂–∏–º (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è) –∏ –±–∞—Ç—á–µ–≤—ã–π —Ä–µ–∂–∏–º
    """
    
    def __init__(self, settings_manager=None):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–µ—Ä–≤–∏—Å–∞
        
        Args:
            settings_manager: –ú–µ–Ω–µ–¥–∂–µ—Ä –Ω–∞—Å—Ç—Ä–æ–µ–∫ –¥–ª—è –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏—Ö LLM
        """
        super().__init__(settings_manager)
        
        # OpenAI –∫–ª—é—á –∏ –∫–ª–∏–µ–Ω—Ç –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É—é—Ç—Å—è –ª–µ–Ω–∏–≤–æ
        self.openai_api_key = None
        self.async_client = None
        
        # üîß –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –î–æ–±–∞–≤–ª—è–µ–º –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–π –∞—Ç—Ä–∏–±—É—Ç max_summary_length
        self.max_summary_length = 150  # –î–µ—Ñ–æ–ª—Ç–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –¥–ª—è –¥–ª–∏–Ω—ã —Å–∞–º–º–∞—Ä–∏
        
        logger.info(f"üìù SummarizationServiceCelery –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
        if settings_manager:
            logger.info(f"   –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –±—É–¥—É—Ç –ø–æ–ª—É—á–µ–Ω—ã –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏ —á–µ—Ä–µ–∑ SettingsManager")
        else:
            logger.warning(f"   ‚ö†Ô∏è SettingsManager –Ω–µ –ø–æ–¥–∫–ª—é—á–µ–Ω. –ë—É–¥—É—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω—ã —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏.")
    
    async def process_async(self, text: str, language: str = "ru", custom_prompt: Optional[str] = None, 
                max_summary_length: Optional[int] = None, **kwargs) -> Dict[str, Any]:
        """
        –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ —Å–æ–∑–¥–∞–µ—Ç –∫—Ä–∞—Ç–∫–æ–µ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ –æ–¥–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞
        """
        try:
            if not text or not text.strip():
                return { "summary": "", "status": "skipped", "reason": "empty_text" }
            
            model, max_tokens, temperature, top_p, settings_max_length = await self._get_model_settings_async()
            summary_length = max_summary_length or settings_max_length or self.max_summary_length
            prompt = self._build_single_prompt(custom_prompt, language, summary_length)

            # –û–±–µ—Å–ø–µ—á–∏–≤–∞–µ–º –Ω–∞–ª–∏—á–∏–µ –∫–ª—é—á–∞ OpenAI
            await self._ensure_openai_key()
            if not self.openai_api_key:
                return { "summary": "–æ—à–∏–±–∫–∞ —Å–∞–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏", "status": "error", "error": "missing_openai_api_key" }

            # –†–µ–∞–ª—å–Ω—ã–π –≤—ã–∑–æ–≤ OpenAI
            response_text = await self._call_openai_api_async(system_prompt=prompt, user_message=text)
            if not response_text:
                return { "summary": "–æ—à–∏–±–∫–∞ —Å–∞–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏", "status": "error", "error": "openai_api_failed" }

            return {
                "summary": response_text,
                "language": language,
                "tokens_used": 0,
                "status": "success"
            }
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ process_async: {e}")
            return { "summary": f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {str(e)}", "status": "error", "error": str(e) }

    async def process_posts_individually_async(self, posts: List[Dict], bot_id: int, language: str = "ru", 
                                  custom_prompt: Optional[str] = None, **kwargs) -> List[Dict[str, Any]]:
        """
        ‚ú® –û–ë–ù–û–í–õ–ï–ù–û: –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –ø–æ—Å—Ç—ã –ø–æ –æ–¥–Ω–æ–º—É –∏—Å–ø–æ–ª—å–∑—É—è unified —Å—Ö–µ–º—É
        """
        logger.info(f"üìù –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω–∞—è —Å–∞–º–º–∞—Ä–∏–∑–∞—Ü–∏—è {len(posts)} –ø–æ—Å—Ç–æ–≤")
        
        # üîß –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ü–æ–ª—É—á–∞–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –±–æ—Ç–∞ –≤–∫–ª—é—á–∞—è –∫–∞—Å—Ç–æ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç –∏ –¥–ª–∏–Ω—É —Å–∞–º–º–∞—Ä–∏
        bot_custom_prompt, bot_max_length = await self._get_bot_summarization_settings(bot_id)
        # –ü–æ–ª—É—á–∞–µ–º —Å–∏—Å—Ç–µ–º–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Å–∏—Å—Ç–µ–º–Ω–æ–π –¥–ª–∏–Ω—ã
        _, _, _, _, settings_max_length = await self._get_model_settings_async()
        if bot_custom_prompt:
            logger.info(f"üéØ –ò—Å–ø–æ–ª—å–∑—É–µ–º –∫–∞—Å—Ç–æ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç –±–æ—Ç–∞ {bot_id} (–¥–ª–∏–Ω–∞: {len(bot_custom_prompt)})")
            custom_prompt = bot_custom_prompt
        else:
            logger.info(f"üìÑ –ö–∞—Å—Ç–æ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è –±–æ—Ç–∞ {bot_id} –Ω–µ –Ω–∞–π–¥–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º –¥–µ—Ñ–æ–ª—Ç–Ω—ã–π")
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω—É—é –¥–ª–∏–Ω—É —Å–∞–º–º–∞—Ä–∏ (–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç: –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –±–æ—Ç–∞ ‚Üí —Å–∏—Å—Ç–µ–º–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ ‚Üí fallback)
        final_max_length = bot_max_length or settings_max_length or self.max_summary_length
        if bot_max_length:
            logger.info(f"üìè –ò—Å–ø–æ–ª—å–∑—É–µ–º –∫–∞—Å—Ç–æ–º–Ω—É—é –¥–ª–∏–Ω—É —Å–∞–º–º–∞—Ä–∏ –±–æ—Ç–∞ {bot_id}: {final_max_length}")
        else:
            logger.info(f"üìè –ò—Å–ø–æ–ª—å–∑—É–µ–º –¥–µ—Ñ–æ–ª—Ç–Ω—É—é –¥–ª–∏–Ω—É —Å–∞–º–º–∞—Ä–∏: {final_max_length}")
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –ø–æ—Å—Ç—ã –≤ PostForSummarization objects
        post_objects = self._convert_to_post_objects(posts, bot_id)
        
        results = []
        for i, post in enumerate(post_objects, 1):
            try:
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º unified schema - PostForSummarization
                text = post.content or ''
                if not text or not text.strip():
                    results.append({
                        "post_id": post.id,  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∞—Ç—Ä–∏–±—É—Ç –æ–±—ä–µ–∫—Ç–∞
                        "public_bot_id": bot_id,
                        "service_name": "summarization",
                        "status": ProcessingStatus.COMPLETED.value,  # –ò—Å–ø–æ–ª—å–∑—É–µ–º enum
                        "payload": {"summary": "", "reason": "empty_text"},
                        "metrics": {}
                    })
                    continue
                
                # –ü–µ—Ä–µ–¥–∞–µ–º post_id, bot_id –∏ –∫–∞—Å—Ç–æ–º–Ω—É—é –¥–ª–∏–Ω—É —Å–∞–º–º–∞—Ä–∏ –¥–ª—è —Ä–µ–∞–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
                result = await self.process_async(text, language, custom_prompt, 
                                                max_summary_length=final_max_length,
                                                post_id=post.id, bot_id=bot_id, **kwargs)
                
                result['post_id'] = post.id  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∞—Ç—Ä–∏–±—É—Ç –æ–±—ä–µ–∫—Ç–∞
                result['public_bot_id'] = bot_id
                result['service_name'] = 'summarization'

                # ‚ú® –û–ë–ù–û–í–õ–ï–ù–û: –ò—Å–ø–æ–ª—å–∑—É–µ–º enum —Å—Ç–∞—Ç—É—Å—ã
                status = ProcessingStatus.COMPLETED.value if result.get('status') == 'success' else ProcessingStatus.FAILED.value
                
                final_result = {
                    'post_id': result.get('post_id'),
                    'public_bot_id': result.get('public_bot_id'),
                    'service_name': 'summarization',
                    'status': status,  # –ò—Å–ø–æ–ª—å–∑—É–µ–º enum —Å—Ç–∞—Ç—É—Å
                    'payload': { 'summary': result.get('summary'), 'language': result.get('language') },
                    'metrics': { 'tokens_used': result.get('tokens_used', 0) }
                }
                if result.get('status') == 'error':
                    final_result['payload']['error'] = result.get('error')

                results.append(final_result)
                
            except Exception as e:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ø–æ—Å—Ç–∞ {i}: {e}")
                results.append({
                    "post_id": post.id,  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∞—Ç—Ä–∏–±—É—Ç –æ–±—ä–µ–∫—Ç–∞
                    "public_bot_id": bot_id,
                    "service_name": "summarization",
                    'status': ProcessingStatus.FAILED.value,  # –ò—Å–ø–æ–ª—å–∑—É–µ–º enum –¥–ª—è –æ—à–∏–±–∫–∏
                    'payload': {'error': str(e)},
                    'metrics': {}
                })
        
        logger.info(f"‚úÖ –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω–∞—è —Å–∞–º–º–∞—Ä–∏–∑–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞: {len(results)} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
        return results
    
    def _convert_to_post_objects(self, posts: List[Dict], bot_id: int) -> List[PostForSummarization]:
        """
        ‚ú® –ù–û–í–û–ï: –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç dict –≤ PostForSummarization objects –∏—Å–ø–æ–ª—å–∑—É—è unified —Å—Ö–µ–º—É
        """
        # –ï—Å–ª–∏ —É–∂–µ PostForSummarization objects, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–∞–∫ –µ—Å—Ç—å
        if posts and isinstance(posts[0], PostForSummarization):
            return posts
        
        # –°–æ–∑–¥–∞–µ–º PostForSummarization –æ–±—ä–µ–∫—Ç—ã —á–µ—Ä–µ–∑ unified —Å—Ö–µ–º—É
        result_posts = []
        for post_data in posts:
            try:
                # –°–æ–∑–¥–∞–µ–º PostForSummarization —Å–æ–≥–ª–∞—Å–Ω–æ schemas.py
                post_obj = PostForSummarization(
                    id=post_data.get('id'),
                    public_bot_id=bot_id,
                    channel_telegram_id=post_data.get('channel_telegram_id', 0),
                    telegram_message_id=post_data.get('telegram_message_id', 0),
                    title=post_data.get('title'),
                    content=post_data.get('content') or post_data.get('text', ''),  # –ü–æ–¥–¥–µ—Ä–∂–∫–∞ legacy –ø–æ–ª—è 'text'
                    media_urls=post_data.get('media_urls', []),
                    views=post_data.get('views', 0),
                    post_date=post_data.get('post_date'),
                    userbot_metadata=post_data.get('userbot_metadata', {}),
                    categories=post_data.get('categories', [])  # –†–µ–∑—É–ª—å—Ç–∞—Ç –∫–∞—Ç–µ–≥–æ—Ä–∏–∑–∞—Ü–∏–∏ –µ—Å–ª–∏ –µ—Å—Ç—å
                )
                result_posts.append(post_obj)
                
            except Exception as e:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è PostForSummarization –¥–ª—è –ø–æ—Å—Ç–∞ {post_data.get('id', 'unknown')}: {e}")
                # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ø—Ä–æ–±–ª–µ–º–∞—Ç–∏—á–Ω—ã–µ –ø–æ—Å—Ç—ã
                continue
        
        logger.info(f"‚úÖ –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ {len(result_posts)} –ø–æ—Å—Ç–æ–≤ –≤ PostForSummarization")
        return result_posts

    async def _ensure_openai_key(self) -> None:
        """–ì–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ—Ç –Ω–∞–ª–∏—á–∏–µ OpenAI API –∫–ª—é—á–∞ –≤ self.openai_api_key."""
        if self.openai_api_key:
            return
        try:
            if self.settings_manager is not None:
                key = await self.settings_manager.get_openai_key()
                self.openai_api_key = key
                return
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å OpenAI –∫–ª—é—á —á–µ—Ä–µ–∑ SettingsManager: {e}")
        # Fallback: –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è –æ–∫—Ä—É–∂–µ–Ω–∏—è
        self.openai_api_key = os.getenv('OPENAI_API_KEY')
    
    async def _call_openai_api_async(self, system_prompt: str, user_message: str) -> Optional[str]:
        """
        –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ –≤—ã–∑—ã–≤–∞–µ—Ç OpenAI API –¥–ª—è –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
        """
        try:
            model, max_tokens, temperature, top_p, settings_max_length = await self._get_model_settings_async()

            # üêû –ò–°–ü–†–ê–í–õ–ï–ù–û: –°–æ–∑–¥–∞–µ–º –∫–ª–∏–µ–Ω—Ç –∏ —è–≤–Ω–æ –∑–∞–∫—Ä—ã–≤–∞–µ–º –µ–≥–æ
            from openai import AsyncOpenAI
            client = AsyncOpenAI(api_key=self.openai_api_key)
            
            try:
                response = await client.chat.completions.create(
                    model=model,
                    messages=[
                        {"role": "system", "content": system_prompt},
                        {"role": "user", "content": user_message}
                    ],
                    max_tokens=max_tokens,
                    temperature=temperature,
                    top_p=top_p
                )
            finally:
                # –Ø–≤–Ω–æ –∑–∞–∫—Ä—ã–≤–∞–µ–º HTTP –∫–ª–∏–µ–Ω—Ç —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å RuntimeError
                await client.close()
            
            return response.choices[0].message.content.strip()

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ Async OpenAI API: {str(e)}")
            return None
        
    async def _get_model_settings_async(self) -> tuple:
        """–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ –ø–æ–ª—É—á–∞–µ—Ç –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –º–æ–¥–µ–ª–∏ –∏–∑ SettingsManager"""
        # üêû FIX: –û–ø—Ä–µ–¥–µ–ª—è–µ–º –±–µ–∑–æ–ø–∞—Å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –ø—Ä—è–º–æ –∑–¥–µ—Å—å
        defaults = {
            'model': 'gpt-4o-mini',
            'max_tokens': 2000,
            'temperature': 0.7,
            'top_p': 1.0,
            'max_summary_length': 150
        }

        if self.settings_manager:
            try:
                config = await self.settings_manager.get_ai_service_config('summarization')
                
                # üîç –î–ï–¢–ê–õ–¨–ù–û–ï –õ–û–ì–ò–†–û–í–ê–ù–ò–ï –ù–ê–°–¢–†–û–ï–ö
                model = config.get('model', defaults['model'])
                max_tokens = int(config.get('max_tokens', defaults['max_tokens']))
                temperature = float(config.get('temperature', defaults['temperature']))
                top_p = float(config.get('top_p', defaults['top_p']))
                max_summary_length = int(config.get('max_summary_length', defaults['max_summary_length']))
                
                logger.info(f"üìã –°–ò–°–¢–ï–ú–ù–´–ï –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ —Å–∞–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏ –∏–∑ SettingsManager (–º–æ–≥—É—Ç –±—ã—Ç—å –ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω—ã –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏ –±–æ—Ç–∞):")
                logger.info(f"   ü§ñ –ú–æ–¥–µ–ª—å: {model} (–æ–∂–∏–¥–∞–ª–æ—Å—å: gpt-4o)")
                logger.info(f"   üéØ Max tokens: {max_tokens} (–æ–∂–∏–¥–∞–ª–æ—Å—å: 2000)")
                logger.info(f"   üå°Ô∏è Temperature: {temperature} (–æ–∂–∏–¥–∞–ª–æ—Å—å: 0.7)")
                logger.info(f"   üé≤ Top_p: {top_p} (–æ–∂–∏–¥–∞–ª–æ—Å—å: 1.0)")
                logger.info(f"   üìè Max summary length: {max_summary_length} (–°–ò–°–¢–ï–ú–ù–ê–Ø, fallback: 150)")
                
                return (model, max_tokens, temperature, top_p, max_summary_length)
                
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –Ω–∞—Å—Ç—Ä–æ–µ–∫: {e}")
                logger.info(f"üìã –ò—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –¥–µ—Ñ–æ–ª—Ç–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ —Å–∞–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏:")
                logger.info(f"   ü§ñ –ú–æ–¥–µ–ª—å: {defaults['model']}")
                logger.info(f"   üéØ Max tokens: {defaults['max_tokens']}")
                logger.info(f"   üå°Ô∏è Temperature: {defaults['temperature']}")
                logger.info(f"   üé≤ Top_p: {defaults['top_p']}")
                logger.info(f"   üìè Max summary length: {defaults['max_summary_length']}")
        else:
            logger.info(f"üìã SettingsManager –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç, –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –¥–µ—Ñ–æ–ª—Ç–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏:")
            logger.info(f"   ü§ñ –ú–æ–¥–µ–ª—å: {defaults['model']}")
            logger.info(f"   üéØ Max tokens: {defaults['max_tokens']}")
            logger.info(f"   üå°Ô∏è Temperature: {defaults['temperature']}")
            logger.info(f"   üé≤ Top_p: {defaults['top_p']}")
            logger.info(f"   üìè Max summary length: {defaults['max_summary_length']}")
        
        return (defaults['model'], defaults['max_tokens'], defaults['temperature'], defaults['top_p'], defaults['max_summary_length'])
    
    def _build_single_prompt(self, custom_prompt: Optional[str], language: str, max_length: int) -> str:
        """–°—Ç—Ä–æ–∏—Ç –ø—Ä–æ–º–ø—Ç –¥–ª—è –æ–¥–∏–Ω–æ—á–Ω–æ–π —Å–∞–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏"""
        # –ë–∞–∑–æ–≤—ã–π –ø—Ä–æ–º–ø—Ç –∏–ª–∏ –∫–∞—Å—Ç–æ–º–Ω—ã–π
        base_prompt = custom_prompt or self._get_default_prompt(language)
        
        # –î–æ–±–∞–≤–ª—è–µ–º –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –ø–æ –¥–ª–∏–Ω–µ
        if max_length:
            length_instruction = f"\n\n–õ–∏–º–∏—Ç –¥–ª–∏–Ω—ã: –ø–æ—Å—Ç–∞—Ä–∞–π—Å—è —É–ª–æ–∂–∏—Ç—å—Å—è –ø—Ä–∏–º–µ—Ä–Ω–æ –≤ {max_length} —Å–∏–º–≤–æ–ª–æ–≤, –Ω–æ –Ω–µ –∂–µ—Ä—Ç–≤—É–π –≤–∞–∂–Ω—ã–º–∏ —á–∞—Å—Ç—è–º–∏ —Ä–∞–¥–∏ —ç—Ç–æ–≥–æ. –õ—É—á—à–µ —Å–ª–µ–≥–∫–∞ –ø—Ä–µ–≤—ã—Å–∏—Ç—å –ª–∏–º–∏—Ç, —á–µ–º –ø–æ—Ç–µ—Ä—è—Ç—å —Å—É—Ç—å –∏–ª–∏ –≤–∫—É—Å —Ç–µ–∫—Å—Ç–∞."
            return f"{base_prompt}{length_instruction}"
        
        return base_prompt
    
    def _build_batch_prompt(self, texts: List[str], custom_prompt: Optional[str], language: str, max_length: int) -> str:
        """–°—Ç—Ä–æ–∏—Ç –ø—Ä–æ–º–ø—Ç –¥–ª—è –±–∞—Ç—á–µ–≤–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏"""
        # –ù–∞—á–∏–Ω–∞–µ–º —Å –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –æ —Ñ–æ—Ä–º–∞—Ç–µ
        prompt = f"""–û–±—Ä–∞–±–æ—Ç–∞–π —Å–ª–µ–¥—É—é—â–∏–µ {len(texts)} —Ç–µ–∫—Å—Ç–æ–≤ –°–¢–†–û–ì–û –ü–†–ò–î–ï–†–ñ–ò–í–ê–Ø–°–¨ –î–õ–Ø –ö–ê–ñ–î–û–ì–û –ò–ó –¢–ï–ö–°–¢–û–í –ò–ù–°–¢–†–£–ö–¶–ò–ò –ù–ò–ñ–ï –∏ –≤–µ—Ä–Ω–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON –º–∞—Å—Å–∏–≤–∞.
–ö–∞–∂–¥—ã–π —ç–ª–µ–º–µ–Ω—Ç –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å –ø–æ–ª–µ "summary".

–§–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞:
[
  {{"summary": "—Ä–µ–∑—É–ª—å—Ç–∞—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–µ–∫—Å—Ç–∞ 1"}},
  {{"summary": "—Ä–µ–∑—É–ª—å—Ç–∞—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–µ–∫—Å—Ç–∞ 2"}},
  ...
]

–ò–ù–°–¢–†–£–ö–¶–ò–Ø –î–õ–Ø –ö–ê–ñ–î–û–ì–û –¢–ï–ö–°–¢–ê:
{custom_prompt or self._get_default_prompt(language)}

–õ–∏–º–∏—Ç –¥–ª–∏–Ω—ã summary: –ø—Ä–∏–º–µ—Ä–Ω–æ {max_length} —Å–∏–º–≤–æ–ª–æ–≤ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ.

–¢–ï–ö–°–¢–´ –î–õ–Ø –û–ë–†–ê–ë–û–¢–ö–ò:
"""
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Ç–µ–∫—Å—Ç—ã —Å –Ω–æ–º–µ—Ä–∞–º–∏
        for i, text in enumerate(texts, 1):
            prompt += f"\n\n=== –¢–ï–ö–°–¢ {i} ===\n{text}"
        
        return prompt
    
    def _parse_batch_response(self, response_text: str, expected_count: int) -> List[str]:
        """–ü–∞—Ä—Å–∏—Ç –±–∞—Ç—á–µ–≤—ã–π –æ—Ç–≤–µ—Ç –æ—Ç OpenAI"""
        summaries = []
        
        try:
            # –ü—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ JSON –≤ –æ—Ç–≤–µ—Ç–µ
            json_text = self._extract_json(response_text)
            if json_text:
                # –ü–∞—Ä—Å–∏–º JSON
                parsed = json.loads(json_text)
                
                # –ò–∑–≤–ª–µ–∫–∞–µ–º summary –∏–∑ –∫–∞–∂–¥–æ–≥–æ —ç–ª–µ–º–µ–Ω—Ç–∞
                if isinstance(parsed, list):
                    for item in parsed:
                        if isinstance(item, dict) and 'summary' in item:
                            summaries.append(item['summary'])
                        elif isinstance(item, str):
                            summaries.append(item)
                
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –±–∞—Ç—á–µ–≤–æ–≥–æ –æ—Ç–≤–µ—Ç–∞: {e}")
        
        # –î–æ–ø–æ–ª–Ω—è–µ–º –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏–µ summary
        while len(summaries) < expected_count:
            summaries.append(f"–ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å —Ç–µ–∫—Å—Ç {len(summaries) + 1}")
        
        # –û–±—Ä–µ–∑–∞–µ–º –ª–∏—à–Ω–∏–µ
        return summaries[:expected_count]
    
    def _extract_json(self, text: str) -> str:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç JSON –∏–∑ —Ç–µ–∫—Å—Ç–∞"""
        try:
            # –ò—â–µ–º –º–∞—Å—Å–∏–≤ JSON
            start = text.find('[')
            if start == -1:
                return ""
            
            # –ù–∞—Ö–æ–¥–∏–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â—É—é –∑–∞–∫—Ä—ã–≤–∞—é—â—É—é —Å–∫–æ–±–∫—É
            bracket_count = 0
            for i in range(start, len(text)):
                if text[i] == '[':
                    bracket_count += 1
                elif text[i] == ']':
                    bracket_count -= 1
                    if bracket_count == 0:
                        return text[start:i+1]
            
            return ""
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è JSON: {e}")
            return ""
    
    def _get_default_prompt(self, language: str) -> str:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –¥–µ—Ñ–æ–ª—Ç–Ω—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è —Å–∞–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏"""
        if language == "ru":
            return """–°–æ–∑–¥–∞–π –∫—Ä–∞—Ç–∫–æ–µ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞, —Å–æ—Ö—Ä–∞–Ω–∏–≤ –æ—Å–Ω–æ–≤–Ω—É—é –∏–¥–µ—é –∏ –∫–ª—é—á–µ–≤—ã–µ –¥–µ—Ç–∞–ª–∏.
–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è:
- –ü–∏—à–∏ –∫—Ä–∞—Ç–∫–æ, –Ω–æ –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω–æ
- –°–æ—Ö—Ä–∞–Ω—è–π –≥–ª–∞–≤–Ω—É—é –º—ã—Å–ª—å –∏ –≤–∞–∂–Ω—ã–µ —Ñ–∞–∫—Ç—ã
- –ò—Å–ø–æ–ª—å–∑—É–π –ø—Ä–æ—Å—Ç–æ–π –∏ –ø–æ–Ω—è—Ç–Ω—ã–π —è–∑—ã–∫
- –ù–µ –¥–æ–±–∞–≤–ª—è–π —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã–µ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ –∏–ª–∏ –æ—Ü–µ–Ω–∫–∏
- –ï—Å–ª–∏ –≤ —Ç–µ–∫—Å—Ç–µ –µ—Å—Ç—å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Ü–∏—Ñ—Ä—ã, –¥–∞—Ç—ã –∏–ª–∏ –∏–º–µ–Ω–∞ - –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –≤–∫–ª—é—á–∞–π –∏—Ö"""
        else:
            return """Create a concise summary of the text, preserving the main idea and key details.
Requirements:
- Write concisely but informatively
- Preserve the main idea and important facts
- Use simple and clear language
- Don't add your own comments or evaluations
- If the text contains specific numbers, dates, or names - be sure to include them"""
    
    def _get_openai_key(self) -> str:
        """–ü–æ–ª—É—á–∞–µ—Ç OpenAI API –∫–ª—é—á –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è"""
        api_key = os.getenv('OPENAI_API_KEY')
        if not api_key:
            raise ValueError("OPENAI_API_KEY environment variable is required") 
        return api_key

    async def _get_bot_summarization_settings(self, bot_id: int) -> tuple[Optional[str], Optional[int]]:
        """
        –ü–æ–ª—É—á–∞–µ—Ç –∫–∞—Å—Ç–æ–º–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ —Å–∞–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏ –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –±–æ—Ç–∞
        
        Args:
            bot_id: ID –ø—É–±–ª–∏—á–Ω–æ–≥–æ –±–æ—Ç–∞
            
        Returns:
            –ö–æ—Ä—Ç–µ–∂ (–∫–∞—Å—Ç–æ–º–Ω—ã–π_–ø—Ä–æ–º–ø—Ç, –º–∞–∫—Å_–¥–ª–∏–Ω–∞_—Å–∞–º–º–∞—Ä–∏) –∏–ª–∏ (None, None) –µ—Å–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã
        """
        try:
            import httpx
            
            # –ü–æ–ª—É—á–∞–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –±–æ—Ç–∞ —á–µ—Ä–µ–∑ Backend API
            async with httpx.AsyncClient(timeout=30) as client:
                response = await client.get(f"http://morningstar_backend:8000/api/public-bots/{bot_id}")
                if response.status_code == 200:
                    bot_data = response.json()
                    
                    # –ü–æ–ª—É—á–∞–µ–º –∫–∞—Å—Ç–æ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç
                    summarization_prompt = bot_data.get("summarization_prompt")
                    custom_prompt = summarization_prompt.strip() if summarization_prompt and summarization_prompt.strip() else None
                    
                    # –ü–æ–ª—É—á–∞–µ–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω—É—é –¥–ª–∏–Ω—É —Å–∞–º–º–∞—Ä–∏
                    max_summary_length = bot_data.get("max_summary_length")
                    custom_max_length = int(max_summary_length) if max_summary_length and str(max_summary_length).isdigit() else None
                    
                    if custom_prompt:
                        logger.info(f"‚úÖ –ü–æ–ª—É—á–µ–Ω –∫–∞—Å—Ç–æ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç —Å–∞–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏ –¥–ª—è –±–æ—Ç–∞ {bot_id}")
                    else:
                        logger.info(f"üìÑ –£ –±–æ—Ç–∞ {bot_id} –Ω–µ—Ç –∫–∞—Å—Ç–æ–º–Ω–æ–≥–æ –ø—Ä–æ–º–ø—Ç–∞ —Å–∞–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏")
                    
                    if custom_max_length:
                        logger.info(f"‚úÖ –ü–æ–ª—É—á–µ–Ω–∞ –∫–∞—Å—Ç–æ–º–Ω–∞—è –¥–ª–∏–Ω–∞ —Å–∞–º–º–∞—Ä–∏ –¥–ª—è –±–æ—Ç–∞ {bot_id}: {custom_max_length}")
                    else:
                        logger.info(f"üìè –£ –±–æ—Ç–∞ {bot_id} –Ω–µ—Ç –∫–∞—Å—Ç–æ–º–Ω–æ–π –¥–ª–∏–Ω—ã —Å–∞–º–º–∞—Ä–∏")
                    
                    return (custom_prompt, custom_max_length)
                else:
                    logger.warning(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –±–æ—Ç–∞ {bot_id}: HTTP {response.status_code}")
                    return (None, None)
                    
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –Ω–∞—Å—Ç—Ä–æ–µ–∫ –±–æ—Ç–∞ {bot_id}: {e}")
            return (None, None) 