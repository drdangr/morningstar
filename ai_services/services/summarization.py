from typing import Dict, Any, Optional, List
from .base import BaseAIService
from openai import AsyncOpenAI
from loguru import logger
import os
import json
import re

class SummarizationService(BaseAIService):
    """–°–µ—Ä–≤–∏—Å –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∫—Ä–∞—Ç–∫–æ–≥–æ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—è –ø–æ—Å—Ç–æ–≤"""
    
    def __init__(
        self,
        model_name: str = "gpt-4",
        max_tokens: int = 4000,
        temperature: float = 0.3,
        max_summary_length: int = 150,
        settings_manager=None
    ):
        super().__init__(model_name, max_tokens, temperature)
        self.max_summary_length = max_summary_length
        self.settings_manager = settings_manager
        self.logger = logger.bind(service="SummarizationService")
        
        # –ö–ª–∏–µ–Ω—Ç OpenAI –±—É–¥–µ—Ç –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏
        self.client = None
        
        self.logger.info("üìù SummarizationService –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
    
    async def _ensure_client(self):
        """üîë –î–ò–ù–ê–ú–ò–ß–ï–°–ö–û–ï —Å–æ–∑–¥–∞–Ω–∏–µ/–æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ OpenAI –∫–ª–∏–µ–Ω—Ç–∞ —Å –∞–∫—Ç—É–∞–ª—å–Ω—ã–º –∫–ª—é—á–æ–º"""
        # –ü–æ–ª—É—á–∞–µ–º –∞–∫—Ç—É–∞–ª—å–Ω—ã–π –∫–ª—é—á
        current_key = None
        
        if self.settings_manager:
            try:
                current_key = await self.settings_manager.get_openai_key()
                self.logger.info("üîë –ü–æ–ª—É—á–µ–Ω –∞–∫—Ç—É–∞–ª—å–Ω—ã–π OpenAI –∫–ª—é—á —á–µ—Ä–µ–∑ SettingsManager")
            except Exception as e:
                self.logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –∫–ª—é—á –∏–∑ SettingsManager: {e}")
        
        # Fallback –Ω–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é –æ–∫—Ä—É–∂–µ–Ω–∏—è —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ SettingsManager –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω
        if not current_key:
            current_key = os.getenv('OPENAI_API_KEY')
            if current_key:
                self.logger.info("‚ö†Ô∏è –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è OpenAI –∫–ª—é—á –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –æ–∫—Ä—É–∂–µ–Ω–∏—è (fallback)")
        
        if not current_key:
            raise ValueError("OpenAI API –∫–ª—é—á –Ω–µ –Ω–∞–π–¥–µ–Ω –Ω–∏ –≤ SettingsManager, –Ω–∏ –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è")
        
        # –°–æ–∑–¥–∞–µ–º/–æ–±–Ω–æ–≤–ª—è–µ–º –∫–ª–∏–µ–Ω—Ç –µ—Å–ª–∏ –∫–ª—é—á –∏–∑–º–µ–Ω–∏–ª—Å—è –∏–ª–∏ –∫–ª–∏–µ–Ω—Ç–∞ –Ω–µ—Ç
        old_key = getattr(self.client, 'api_key', None) if self.client else None
        need_update = not self.client or old_key != current_key
        
        if need_update:
            self.client = AsyncOpenAI(api_key=current_key)
            self.logger.info(f"üîÑ OpenAI –∫–ª–∏–µ–Ω—Ç —Å–æ–∑–¥–∞–Ω/–æ–±–Ω–æ–≤–ª–µ–Ω —Å –∫–ª—é—á–æ–º {current_key[-10:]}")
        else:
            self.logger.debug(f"‚úÖ OpenAI –∫–ª–∏–µ–Ω—Ç –∞–∫—Ç—É–∞–ª–µ–Ω (–∫–ª—é—á {current_key[-10:]})")
    
    async def close(self):
        """
        üîí –Ø–í–ù–û–ï –∑–∞–∫—Ä—ã—Ç–∏–µ OpenAI –∫–ª–∏–µ–Ω—Ç–∞ –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è –æ—à–∏–±–æ–∫ Event loop is closed
        """
        if self.client:
            try:
                await self.client.close()
                self.logger.info("üîí SummarizationService: OpenAI –∫–ª–∏–µ–Ω—Ç –∑–∞–∫—Ä—ã—Ç")
            except Exception as e:
                self.logger.warning(f"‚ö†Ô∏è SummarizationService: –æ—à–∏–±–∫–∞ –∑–∞–∫—Ä—ã—Ç–∏—è OpenAI –∫–ª–∏–µ–Ω—Ç–∞: {e}")
            finally:
                self.client = None
    
    async def process(
        self,
        text: str,
        language: str = "ru",
        custom_prompt: Optional[str] = None,
        max_summary_length: Optional[int] = None,
        **kwargs
    ) -> Dict[str, Any]:
        """–°–æ–∑–¥–∞–Ω–∏–µ –∫—Ä–∞—Ç–∫–æ–≥–æ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—è –æ–¥–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞"""
        try:
            # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º OpenAI –∫–ª–∏–µ–Ω—Ç –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏
            await self._ensure_client()
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤–∞–ª–∏–¥–Ω–æ—Å—Ç—å –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
            if not text or not text.strip():
                return {
                    "summary": "",
                    "status": "skipped",
                    "reason": "empty_text"
                }
            
            # –ü–æ–ª—É—á–∞–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∏–∑ SettingsManager –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ–º –¥–µ—Ñ–æ–ª—Ç–Ω—ã–µ
            model, max_tokens, temperature, top_p = await self._get_model_settings()
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º –ø—Ä–æ–º–ø—Ç
            summary_length = max_summary_length or self.max_summary_length
            prompt = self._build_single_prompt(custom_prompt, language, summary_length)
            
            # –í—ã–∑—ã–≤–∞–µ–º OpenAI API
            response = await self.client.chat.completions.create(
                model=model,
                messages=[
                    {"role": "system", "content": prompt},
                    {"role": "user", "content": text}
                ],
                max_tokens=max_tokens,
                temperature=temperature,
                top_p=top_p
            )
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            summary = response.choices[0].message.content.strip()
            
            return {
                "summary": summary,
                "language": language,
                "tokens_used": response.usage.total_tokens,
                "status": "success"
            }
            
        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ process: {e}")
            return {
                "summary": f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {str(e)}",
                "status": "error",
                "error": str(e)
            }
    
    async def process_batch(
        self,
        texts: List[str],
        language: str = "ru",
        custom_prompt: Optional[str] = None,
        max_summary_length: Optional[int] = None,
        **kwargs
    ) -> List[Dict[str, Any]]:
        """–ë–∞—Ç—á–µ–≤–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–æ–≤ –æ–¥–Ω–∏–º –∑–∞–ø—Ä–æ—Å–æ–º"""
        
        if not texts:
            return []
        
        self.logger.info(f"üöÄ –ë–∞—Ç—á–µ–≤–∞—è —Å–∞–º–º–∞—Ä–∏–∑–∞—Ü–∏—è {len(texts)} —Ç–µ–∫—Å—Ç–æ–≤")
        
        try:
            # –ü–æ–ª—É—á–∞–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
            model, max_tokens, temperature, top_p = await self._get_model_settings()
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º –±–∞—Ç—á–µ–≤—ã–π –ø—Ä–æ–º–ø—Ç
            summary_length = max_summary_length or self.max_summary_length
            batch_prompt = self._build_batch_prompt(texts, custom_prompt, language, summary_length)
            
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å –∫ OpenAI
            response = await self.client.chat.completions.create(
                model=model,
                messages=[
                    {"role": "user", "content": batch_prompt}
                ],
                max_tokens=max_tokens * 2,  # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –¥–ª—è –±–∞—Ç—á–∞
                temperature=temperature,
                top_p=top_p
            )
            
            # –ü–∞—Ä—Å–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            response_text = response.choices[0].message.content.strip()
            summaries = self._parse_batch_response(response_text, len(texts))
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            total_tokens = response.usage.total_tokens
            tokens_per_text = total_tokens // len(texts) if texts else 0
            
            results = []
            for i, summary in enumerate(summaries):
                results.append({
                    "summary": summary,
                    "language": language,
                    "tokens_used": tokens_per_text,
                    "status": "success"
                })
            
            self.logger.info(f"‚úÖ –ë–∞—Ç—á–µ–≤–∞—è —Å–∞–º–º–∞—Ä–∏–∑–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞: {len(results)} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
            return results
            
        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –±–∞—Ç—á–µ–≤–æ–π —Å–∞–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏: {e}")
            
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—à–∏–±–∫–∏ –¥–ª—è –≤—Å–µ—Ö —Ç–µ–∫—Å—Ç–æ–≤
            return [{
                "summary": f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–µ–∫—Å—Ç–∞ {i+1}",
                "language": language,
                "tokens_used": 0,
                "status": "error",
                "error": str(e)
            } for i in range(len(texts))]
    
    async def _get_model_settings(self):
        """–ü–æ–ª—É—á–∞–µ—Ç –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –º–æ–¥–µ–ª–∏ –∏–∑ SettingsManager –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –¥–µ—Ñ–æ–ª—Ç–Ω—ã–µ"""
        if self.settings_manager:
            try:
                config = await self.settings_manager.get_ai_service_config('summarization')
                return (
                    config['model'],
                    config['max_tokens'],
                    config['temperature'],
                    config.get('top_p', 1.0)
                )
            except Exception as e:
                self.logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –Ω–∞—Å—Ç—Ä–æ–µ–∫: {e}")
        
        # –î–µ—Ñ–æ–ª—Ç–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
        return (
            self.model_name,
            self.max_tokens,
            self.temperature,
            1.0
        )
    
    def _build_single_prompt(self, custom_prompt: Optional[str], language: str, max_length: int) -> str:
        """–°—Ç—Ä–æ–∏—Ç –ø—Ä–æ–º–ø—Ç –¥–ª—è –æ–¥–∏–Ω–æ—á–Ω–æ–π —Å–∞–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏"""
        # –ë–∞–∑–æ–≤—ã–π –ø—Ä–æ–º–ø—Ç –∏–ª–∏ –∫–∞—Å—Ç–æ–º–Ω—ã–π
        base_prompt = custom_prompt or self._get_default_prompt(language)
        
        # –î–æ–±–∞–≤–ª—è–µ–º –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –ø–æ –¥–ª–∏–Ω–µ
        if max_length:
            length_instruction = f"\n\n–õ–∏–º–∏—Ç –¥–ª–∏–Ω—ã: –ø–æ—Å—Ç–∞—Ä–∞–π—Å—è —É–ª–æ–∂–∏—Ç—å—Å—è –ø—Ä–∏–º–µ—Ä–Ω–æ –≤ {max_length} —Å–∏–º–≤–æ–ª–æ–≤, –Ω–æ –Ω–µ –∂–µ—Ä—Ç–≤—É–π –≤–∞–∂–Ω—ã–º–∏ —á–∞—Å—Ç—è–º–∏ —Ä–∞–¥–∏ —ç—Ç–æ–≥–æ. –õ—É—á—à–µ —Å–ª–µ–≥–∫–∞ –ø—Ä–µ–≤—ã—Å–∏—Ç—å –ª–∏–º–∏—Ç, —á–µ–º –ø–æ—Ç–µ—Ä—è—Ç—å —Å—É—Ç—å –∏–ª–∏ –≤–∫—É—Å —Ç–µ–∫—Å—Ç–∞."
            return f"{base_prompt}{length_instruction}"
        
        return base_prompt
    
    def _build_batch_prompt(self, texts: List[str], custom_prompt: Optional[str], language: str, max_length: int) -> str:
        """–°—Ç—Ä–æ–∏—Ç –ø—Ä–æ–º–ø—Ç –¥–ª—è –±–∞—Ç—á–µ–≤–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏"""
        # –ù–∞—á–∏–Ω–∞–µ–º —Å –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –æ —Ñ–æ—Ä–º–∞—Ç–µ
        prompt = f"""–û–±—Ä–∞–±–æ—Ç–∞–π —Å–ª–µ–¥—É—é—â–∏–µ {len(texts)} —Ç–µ–∫—Å—Ç–æ–≤ –°–¢–†–û–ì–û –ü–†–ò–î–ï–†–ñ–ò–í–ê–Ø–°–¨ –î–õ–Ø –ö–ê–ñ–î–û–ì–û –ò–ó –¢–ï–ö–°–¢–û–í–ò–ù–°–¢–†–£–ö–¶–ò–ò –ù–ò–ñ–ï –∏ –≤–µ—Ä–Ω–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON –º–∞—Å—Å–∏–≤–∞.
–ö–∞–∂–¥—ã–π —ç–ª–µ–º–µ–Ω—Ç –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å –ø–æ–ª–µ "summary".

–§–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞:
[
  {{"summary": "—Ä–µ–∑—É–ª—å—Ç–∞—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–µ–∫—Å—Ç–∞ 1"}},
  {{"summary": "—Ä–µ–∑—É–ª—å—Ç–∞—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–µ–∫—Å—Ç–∞ 2"}},
  ...
]

–ò–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∫–∞–∂–¥–æ–≥–æ —Ç–µ–∫—Å—Ç–∞:
"""
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∫–∞—Å—Ç–æ–º–Ω—ã–π –∏–ª–∏ –¥–µ—Ñ–æ–ª—Ç–Ω—ã–π –ø—Ä–æ–º–ø—Ç
        base_prompt = custom_prompt or self._get_default_prompt(language)
        prompt += base_prompt
        
        # –î–æ–±–∞–≤–ª—è–µ–º –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –ø–æ –¥–ª–∏–Ω–µ
        if max_length:
            prompt += f"\n\n–õ–∏–º–∏—Ç –¥–ª–∏–Ω—ã: –ø–æ—Å—Ç–∞—Ä–∞–π—Å—è —É–ª–æ–∂–∏—Ç—å—Å—è –ø—Ä–∏–º–µ—Ä–Ω–æ –≤ {max_length} —Å–∏–º–≤–æ–ª–æ–≤, –Ω–æ –Ω–µ –∂–µ—Ä—Ç–≤—É–π –≤–∞–∂–Ω—ã–º–∏ —á–∞—Å—Ç—è–º–∏ —Ä–∞–¥–∏ —ç—Ç–æ–≥–æ. –õ—É—á—à–µ —Å–ª–µ–≥–∫–∞ –ø—Ä–µ–≤—ã—Å–∏—Ç—å –ª–∏–º–∏—Ç, —á–µ–º –ø–æ—Ç–µ—Ä—è—Ç—å —Å—É—Ç—å –∏–ª–∏ –≤–∫—É—Å —Ç–µ–∫—Å—Ç–∞."
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Ç–µ–∫—Å—Ç—ã
        prompt += "\n\n–¢–ï–ö–°–¢–´ –î–õ–Ø –û–ë–†–ê–ë–û–¢–ö–ò:"
        for i, text in enumerate(texts, 1):
            prompt += f"\n\n--- –¢–ï–ö–°–¢ {i} ---\n{text}"
        
        return prompt
    
    def _parse_batch_response(self, response_text: str, expected_count: int) -> List[str]:
        """–ü–∞—Ä—Å–∏—Ç –æ—Ç–≤–µ—Ç –±–∞—Ç—á–µ–≤–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏"""
        try:
            # –ò–∑–≤–ª–µ–∫–∞–µ–º JSON –∏–∑ –æ—Ç–≤–µ—Ç–∞
            json_text = self._extract_json(response_text)
            
            # –ü–∞—Ä—Å–∏–º JSON
            data = json.loads(json_text)
            
            if not isinstance(data, list):
                raise ValueError("–û—Ç–≤–µ—Ç –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –º–∞—Å—Å–∏–≤–æ–º")
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Å–∞–º–º–∞—Ä–∏
            summaries = []
            for i in range(expected_count):
                if i < len(data) and isinstance(data[i], dict):
                    summary = data[i].get('summary', f'–û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Å–∞–º–º–∞—Ä–∏ {i+1}')
                else:
                    summary = f'–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç —Å–∞–º–º–∞—Ä–∏ –¥–ª—è —Ç–µ–∫—Å—Ç–∞ {i+1}'
                summaries.append(summary)
            
            return summaries
            
        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –æ—Ç–≤–µ—Ç–∞: {e}")
            self.logger.debug(f"–û—Ç–≤–µ—Ç: {response_text[:500]}...")
            
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—à–∏–±–∫–∏ –¥–ª—è –≤—Å–µ—Ö —Ç–µ–∫—Å—Ç–æ–≤
            return [f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –æ—Ç–≤–µ—Ç–∞ –¥–ª—è —Ç–µ–∫—Å—Ç–∞ {i+1}" for i in range(expected_count)]
    
    def _extract_json(self, text: str) -> str:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç JSON –∏–∑ —Ç–µ–∫—Å—Ç–∞, –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—è —Ä–∞–∑–Ω—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã"""
        # JSON –≤ markdown –±–ª–æ–∫–µ ```json
        match = re.search(r'```json\s*\n(.*?)\n```', text, re.DOTALL)
        if match:
            return match.group(1).strip()
        
        # JSON –≤ –±–ª–æ–∫–µ –±–µ–∑ —è–∑—ã–∫–∞ ```
        match = re.search(r'```\s*\n(.*?)\n```', text, re.DOTALL)
        if match:
            potential_json = match.group(1).strip()
            if potential_json.startswith('[') or potential_json.startswith('{'):
                return potential_json
        
        # –ß–∏—Å—Ç—ã–π JSON
        if text.strip().startswith('[') or text.strip().startswith('{'):
            return text.strip()
        
        # –ò—â–µ–º JSON –º–∞—Å—Å–∏–≤ –≤ —Ç–µ–∫—Å—Ç–µ
        match = re.search(r'(\[.*?\])', text, re.DOTALL)
        if match:
            return match.group(1)
        
        # –ù–µ –Ω–∞—à–ª–∏ JSON
        return text
    
    def _get_default_prompt(self, language: str) -> str:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –¥–µ—Ñ–æ–ª—Ç–Ω—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è —è–∑—ã–∫–∞"""
        prompts = {
            "ru": """–°–æ–∑–¥–∞–π –∫—Ä–∞—Ç–∫–æ–µ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞.
–°–æ—Ö—Ä–∞–Ω–∏ –∫–ª—é—á–µ–≤—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏ –≤–∞–∂–Ω—ã–µ –¥–µ—Ç–∞–ª–∏.
–ò—Å–ø–æ–ª—å–∑—É–π –Ω–µ–π—Ç—Ä–∞–ª—å–Ω—ã–π —Ç–æ–Ω.""",
            
            "en": """Create a summary of the text.
Preserve key information and important details.
Use a neutral tone."""
        }
        
        return prompts.get(language, prompts["ru"]) 