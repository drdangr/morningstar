from typing import Dict, Any, Optional
from .base import BaseAIService
from openai import AsyncOpenAI
from loguru import logger
import os
import json
import re

class SummarizationService(BaseAIService):
    """–°–µ—Ä–≤–∏—Å –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∫—Ä–∞—Ç–∫–æ–≥–æ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—è –ø–æ—Å—Ç–æ–≤"""
    
    def __init__(
        self,
        model_name: str = "gpt-4",
        max_tokens: int = 4000,
        temperature: float = 0.3,
        max_summary_length: int = 150,
        settings_manager=None
    ):
        super().__init__(model_name, max_tokens, temperature)
        self.max_summary_length = max_summary_length
        self.settings_manager = settings_manager
        self.logger = logger.bind(service="SummarizationService")
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–ª–∏–µ–Ω—Ç OpenAI
        api_key = os.getenv('OPENAI_API_KEY')
        if not api_key:
            raise ValueError("OPENAI_API_KEY environment variable is required")
        self.client = AsyncOpenAI(api_key=api_key)
        
        self.logger.info(f"üìù SummarizationService –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
        self.logger.info(f"   –ú–æ–¥–µ–ª—å: {model_name}")
        self.logger.info(f"   Max tokens: {max_tokens}")
        self.logger.info(f"   Temperature: {temperature}")
        if settings_manager:
            self.logger.info(f"   SettingsManager: –ø–æ–¥–∫–ª—é—á–µ–Ω –¥–ª—è –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏—Ö –Ω–∞—Å—Ç—Ä–æ–µ–∫")
        else:
            self.logger.info(f"   SettingsManager: –Ω–µ –ø–æ–¥–∫–ª—é—á–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –ø–µ—Ä–µ–¥–∞–Ω–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã")
    
    async def process(
        self,
        text: str,
        language: str = "ru",
        custom_prompt: Optional[str] = None,
        max_summary_length: Optional[int] = None,
        **kwargs
    ) -> Dict[str, Any]:
        """–°–æ–∑–¥–∞–Ω–∏–µ –∫—Ä–∞—Ç–∫–æ–≥–æ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ —Å –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–º–∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏"""
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤–∞–ª–∏–¥–Ω–æ—Å—Ç—å –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
            if not await self.validate_input(text):
                return {
                    "summary": "",
                    "status": "skipped",
                    "reason": "empty_text",
                    "original_length": 0,
                    "summary_length": 0
                }
            
            # –ü–æ–ª—É—á–∞–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏
            if self.settings_manager:
                try:
                    summarization_config = await self.settings_manager.get_ai_service_config('summarization')
                    model = summarization_config['model']
                    max_tokens = summarization_config['max_tokens']
                    temperature = summarization_config['temperature']
                    self.logger.debug(f"ü§ñ –ò—Å–ø–æ–ª—å–∑—É–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏: {model}, tokens={max_tokens}, temp={temperature}")
                except Exception as e:
                    self.logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –Ω–∞—Å—Ç—Ä–æ–µ–∫ —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏: {e}, –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø–µ—Ä–µ–¥–∞–Ω–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã")
                    model = self.model_name
                    max_tokens = self.max_tokens
                    temperature = self.temperature
            else:
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–µ—Ä–µ–¥–∞–Ω–Ω—ã–µ –≤ –∫–æ–Ω—Å—Ç—Ä—É–∫—Ç–æ—Ä
                model = self.model_name
                max_tokens = self.max_tokens
                temperature = self.temperature
                self.logger.debug(f"ü§ñ –ò—Å–ø–æ–ª—å–∑—É–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∏–∑ –∫–æ–Ω—Å—Ç—Ä—É–∫—Ç–æ—Ä–∞: {model}, tokens={max_tokens}, temp={temperature}")
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º –ø—Ä–æ–º–ø—Ç
            prompt = custom_prompt or self._get_default_prompt(language)
            
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–µ—Ä–µ–¥–∞–Ω–Ω—É—é –¥–ª–∏–Ω—É –∏–ª–∏ –¥–µ—Ñ–æ–ª—Ç–Ω—É—é
            summary_length = max_summary_length or self.max_summary_length
            
            # –î–æ–±–∞–≤–ª—è–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—é –ø–æ –¥–ª–∏–Ω–µ –∫ –∫–∞—Å—Ç–æ–º–Ω–æ–º—É –ø—Ä–æ–º–ø—Ç—É
            if custom_prompt and summary_length:
                # –ë–æ–ª–µ–µ –ø—Ä—è–º–∞—è –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è –¥–ª—è AI
                min_sentences = 2 if summary_length >= 200 else 1
                max_sentences = 4 if summary_length >= 400 else 3
                length_instruction = f"\n\n–û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û–ï –¢–†–ï–ë–û–í–ê–ù–ò–ï: –†–µ–∑—é–º–µ –¥–æ–ª–∂–Ω–æ —Å–æ—Å—Ç–æ—è—Ç—å –∏–∑ {min_sentences}-{max_sentences} –ø–æ–ª–Ω—ã—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π. –û–±—â–∞—è –¥–ª–∏–Ω–∞ —Ä–µ–∑—é–º–µ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –≤ –¥–∏–∞–ø–∞–∑–æ–Ω–µ {summary_length // 2}-{summary_length} —Å–∏–º–≤–æ–ª–æ–≤. –ù–ï —Å–æ–∑–¥–∞–≤–∞–π —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–µ —Ä–µ–∑—é–º–µ –∏–∑ –æ–¥–Ω–æ–≥–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è!"
                prompt = f"{custom_prompt}{length_instruction}"
            
            # –í—ã–∑—ã–≤–∞–µ–º OpenAI API —Å –Ω–æ–≤—ã–º —Å–∏–Ω—Ç–∞–∫—Å–∏—Å–æ–º
            response = await self.client.chat.completions.create(
                model=model,
                messages=[
                    {"role": "system", "content": prompt},
                    {"role": "user", "content": text}
                ],
                max_tokens=max_tokens,
                temperature=temperature
            )
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            summary = response.choices[0].message.content.strip()
            
            return {
                "summary": summary,
                "language": language,
                "tokens_used": response.usage.total_tokens,
                "status": "success"
            }
            
        except Exception as e:
            return await self.handle_error(e, {"text_length": len(text)})
    
    async def process_batch(
        self,
        texts: list[str],
        language: str = "ru",
        custom_prompt: Optional[str] = None,
        max_summary_length: Optional[int] = None,
        **kwargs
    ) -> list[Dict[str, Any]]:
        """–ù–ê–°–¢–û–Ø–©–ê–Ø –ø–∞–∫–µ—Ç–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –ø–æ—Å—Ç–æ–≤ - –æ–¥–Ω–∏–º –∑–∞–ø—Ä–æ—Å–æ–º –∫ OpenAI"""
        
        if not texts:
            return []
        
        self.logger.info(f"üöÄ –ë–ê–¢–ß–ï–í–ê–Ø —Å–∞–º–º–∞—Ä–∏–∑–∞—Ü–∏—è {len(texts)} —Ç–µ–∫—Å—Ç–æ–≤ –æ–¥–Ω–∏–º –∑–∞–ø—Ä–æ—Å–æ–º")
        
        try:
            # –ü–æ–ª—É—á–∞–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏
            if self.settings_manager:
                try:
                    summarization_config = await self.settings_manager.get_ai_service_config('summarization')
                    model = summarization_config['model']
                    max_tokens = summarization_config['max_tokens']
                    temperature = summarization_config['temperature']
                    self.logger.debug(f"ü§ñ –ë–∞—Ç—á: –∏—Å–ø–æ–ª—å–∑—É–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏: {model}, tokens={max_tokens}, temp={temperature}")
                except Exception as e:
                    self.logger.warning(f"‚ö†Ô∏è –ë–∞—Ç—á: –æ—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –Ω–∞—Å—Ç—Ä–æ–µ–∫ —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏: {e}, –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø–µ—Ä–µ–¥–∞–Ω–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã")
                    model = self.model_name
                    max_tokens = self.max_tokens
                    temperature = self.temperature
            else:
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–µ—Ä–µ–¥–∞–Ω–Ω—ã–µ –≤ –∫–æ–Ω—Å—Ç—Ä—É–∫—Ç–æ—Ä
                model = self.model_name
                max_tokens = self.max_tokens
                temperature = self.temperature
                self.logger.debug(f"ü§ñ –ë–∞—Ç—á: –∏—Å–ø–æ–ª—å–∑—É–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∏–∑ –∫–æ–Ω—Å—Ç—Ä—É–∫—Ç–æ—Ä–∞: {model}, tokens={max_tokens}, temp={temperature}")
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º –ø—Ä–æ–º–ø—Ç –¥–ª—è –±–∞—Ç—á–µ–≤–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
            base_prompt = custom_prompt or self._get_default_prompt(language)
            
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–µ—Ä–µ–¥–∞–Ω–Ω—É—é –¥–ª–∏–Ω—É –∏–ª–∏ –¥–µ—Ñ–æ–ª—Ç–Ω—É—é
            summary_length = max_summary_length or self.max_summary_length
            
            # –î–æ–±–∞–≤–ª—è–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—é –ø–æ –¥–ª–∏–Ω–µ –∫ –∫–∞—Å—Ç–æ–º–Ω–æ–º—É –ø—Ä–æ–º–ø—Ç—É
            if custom_prompt and summary_length:
                # –ë–æ–ª–µ–µ –ø—Ä—è–º–∞—è –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è –¥–ª—è AI
                min_sentences = 2 if summary_length >= 200 else 1
                max_sentences = 4 if summary_length >= 400 else 3
                length_instruction = f"\n\n–û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û–ï –¢–†–ï–ë–û–í–ê–ù–ò–ï: –†–µ–∑—é–º–µ –¥–æ–ª–∂–Ω–æ —Å–æ—Å—Ç–æ—è—Ç—å –∏–∑ {min_sentences}-{max_sentences} –ø–æ–ª–Ω—ã—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π. –û–±—â–∞—è –¥–ª–∏–Ω–∞ —Ä–µ–∑—é–º–µ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –≤ –¥–∏–∞–ø–∞–∑–æ–Ω–µ {summary_length // 2}-{summary_length} —Å–∏–º–≤–æ–ª–æ–≤. –ù–ï —Å–æ–∑–¥–∞–≤–∞–π —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–µ —Ä–µ–∑—é–º–µ –∏–∑ –æ–¥–Ω–æ–≥–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è!"
                base_prompt = f"{custom_prompt}{length_instruction}"
            
            # –°–æ–∑–¥–∞–µ–º –±–∞—Ç—á–µ–≤—ã–π –ø—Ä–æ–º–ø—Ç
            batch_prompt = f"""{base_prompt}

–í–ê–ñ–ù–û: –û–±—Ä–∞–±–æ—Ç–∞–π —Å–ª–µ–¥—É—é—â–∏–µ {len(texts)} —Ç–µ–∫—Å—Ç–æ–≤ –∏ –≤–µ—Ä–Ω–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON –º–∞—Å—Å–∏–≤–∞.
–ö–∞–∂–¥—ã–π —ç–ª–µ–º–µ–Ω—Ç –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å –ø–æ–ª–µ "summary" —Å –∫—Ä–∞—Ç–∫–∏–º —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–µ–≥–æ —Ç–µ–∫—Å—Ç–∞.

–§–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞:
[
  {{"summary": "–∫—Ä–∞—Ç–∫–æ–µ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ 1"}},
  {{"summary": "–∫—Ä–∞—Ç–∫–æ–µ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ 2"}},
  ...
]

–¢–ï–ö–°–¢–´ –î–õ–Ø –û–ë–†–ê–ë–û–¢–ö–ò:"""

            # –î–æ–±–∞–≤–ª—è–µ–º –≤—Å–µ —Ç–µ–∫—Å—Ç—ã —Å –Ω—É–º–µ—Ä–∞—Ü–∏–µ–π
            for i, text in enumerate(texts, 1):
                batch_prompt += f"\n\n--- –¢–ï–ö–°–¢ {i} ---\n{text}"
            
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –±–∞—Ç—á–µ–≤—ã–π –∑–∞–ø—Ä–æ—Å –∫ OpenAI
            response = await self.client.chat.completions.create(
                model=model,
                messages=[
                    {"role": "user", "content": batch_prompt}
                ],
                max_tokens=max_tokens * 2,  # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –ª–∏–º–∏—Ç –¥–ª—è –±–∞—Ç—á–∞
                temperature=temperature
            )
            
            # –ü–∞—Ä—Å–∏–º JSON –æ—Ç–≤–µ—Ç
            response_text = response.choices[0].message.content.strip()
            
            # üîß –£–ú–ù–´–ô –ü–ê–†–°–ò–ù–ì: –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º JSON –≤ markdown –±–ª–æ–∫–∞—Ö
            def extract_json_from_response(text: str) -> str:
                """–ò–∑–≤–ª–µ–∫–∞–µ—Ç JSON –∏–∑ –æ—Ç–≤–µ—Ç–∞ OpenAI, –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—è markdown –±–ª–æ–∫–∏"""
                
                # –í–∞—Ä–∏–∞–Ω—Ç 1: JSON –≤ markdown –±–ª–æ–∫–µ ```json
                json_match = re.search(r'```json\s*\n(.*?)\n```', text, re.DOTALL)
                if json_match:
                    self.logger.info("üìù –ù–∞–π–¥–µ–Ω JSON –≤ markdown –±–ª–æ–∫–µ ```json")
                    return json_match.group(1).strip()
                
                # –í–∞—Ä–∏–∞–Ω—Ç 2: JSON –≤ –±–ª–æ–∫–µ –±–µ–∑ —è–∑—ã–∫–∞ ```
                json_match = re.search(r'```\s*\n(.*?)\n```', text, re.DOTALL)
                if json_match:
                    potential_json = json_match.group(1).strip()
                    if potential_json.startswith('[') or potential_json.startswith('{'):
                        self.logger.info("üìù –ù–∞–π–¥–µ–Ω JSON –≤ markdown –±–ª–æ–∫–µ ```")
                        return potential_json
                
                # –í–∞—Ä–∏–∞–Ω—Ç 3: –ß–∏—Å—Ç—ã–π JSON (–Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å [ –∏–ª–∏ {)
                if text.startswith('[') or text.startswith('{'):
                    self.logger.info("üìù –ù–∞–π–¥–µ–Ω —á–∏—Å—Ç—ã–π JSON")
                    return text
                
                # –í–∞—Ä–∏–∞–Ω—Ç 4: –ò—â–µ–º JSON –≤ —Ç–µ–∫—Å—Ç–µ –ø–æ –ø–∞—Ç—Ç–µ—Ä–Ω—É
                json_match = re.search(r'(\[.*?\])', text, re.DOTALL)
                if json_match:
                    self.logger.info("üìù –ù–∞–π–¥–µ–Ω JSON –ø–æ –ø–∞—Ç—Ç–µ—Ä–Ω—É –≤ —Ç–µ–∫—Å—Ç–µ")
                    return json_match.group(1)
                
                self.logger.warning("‚ö†Ô∏è JSON –Ω–µ –Ω–∞–π–¥–µ–Ω, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∏—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç")
                return text
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º JSON –∏–∑ –æ—Ç–≤–µ—Ç–∞
            clean_json = extract_json_from_response(response_text)
            
            # –ü—Ä–æ–±—É–µ–º —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å JSON
            try:
                summaries_data = json.loads(clean_json)
                
                if not isinstance(summaries_data, list):
                    raise ValueError("–û—Ç–≤–µ—Ç –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –º–∞—Å—Å–∏–≤–æ–º")
                
                if len(summaries_data) != len(texts):
                    self.logger.warning(f"‚ö†Ô∏è –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ ({len(summaries_data)}) –Ω–µ —Å–æ–≤–ø–∞–¥–∞–µ—Ç —Å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º —Ç–µ–∫—Å—Ç–æ–≤ ({len(texts)})")
                
                # –§–æ—Ä–º–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
                results = []
                total_tokens = response.usage.total_tokens
                tokens_per_text = total_tokens // len(texts) if texts else 0
                
                for i, text in enumerate(texts):
                    if i < len(summaries_data) and isinstance(summaries_data[i], dict):
                        summary = summaries_data[i].get('summary', '')
                    else:
                        summary = f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–µ–∫—Å—Ç–∞ {i+1}"
                        self.logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Å–∞–º–º–∞—Ä–∏–∑–∞—Ü–∏—é –¥–ª—è —Ç–µ–∫—Å—Ç–∞ {i+1}")
                    
                    results.append({
                        "summary": summary,
                        "language": language,
                        "tokens_used": tokens_per_text,
                        "status": "success"
                    })
                
                self.logger.info(f"‚úÖ –ë–ê–¢–ß–ï–í–ê–Ø —Å–∞–º–º–∞—Ä–∏–∑–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞: {len(results)} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤, {total_tokens} —Ç–æ–∫–µ–Ω–æ–≤")
                return results
                
            except json.JSONDecodeError as e:
                self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON –æ—Ç–≤–µ—Ç–∞: {e}")
                self.logger.error(f"–û—Ç–≤–µ—Ç OpenAI: {response_text[:500]}...")
                
                # Fallback: –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—É—Å—Ç—ã–µ —Å–∞–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏
                results = []
                for i, text in enumerate(texts):
                    results.append({
                        "summary": f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –¥–ª—è —Ç–µ–∫—Å—Ç–∞ {i+1}",
                        "language": language,
                        "tokens_used": 0,
                        "status": "error"
                    })
                return results
                
        except Exception as e:
            self.logger.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –±–∞—Ç—á–µ–≤–æ–π —Å–∞–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏: {e}")
            
            # Fallback: –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—à–∏–±–∫–∏ –¥–ª—è –≤—Å–µ—Ö —Ç–µ–∫—Å—Ç–æ–≤
            results = []
            for i, text in enumerate(texts):
                results.append({
                    "summary": f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –¥–ª—è —Ç–µ–∫—Å—Ç–∞ {i+1}",
                    "language": language,
                    "tokens_used": 0,
                    "status": "error"
                })
            return results
    
    def _get_default_prompt(self, language: str) -> str:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–≥–æ –ø—Ä–æ–º–ø—Ç–∞ –¥–ª—è —è–∑—ã–∫–∞"""
        
        prompts = {
            "ru": f"""–°–æ–∑–¥–∞–π –∫—Ä–∞—Ç–∫–æ–µ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –¥–ª–∏–Ω–æ–π –Ω–µ –±–æ–ª–µ–µ {self.max_summary_length} —Å–∏–º–≤–æ–ª–æ–≤.
            –°–æ—Ö—Ä–∞–Ω–∏ –∫–ª—é—á–µ–≤—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏ –≤–∞–∂–Ω—ã–µ –¥–µ—Ç–∞–ª–∏.
            –ò—Å–ø–æ–ª—å–∑—É–π –Ω–µ–π—Ç—Ä–∞–ª—å–Ω—ã–π —Ç–æ–Ω.
            –§–æ—Ä–º–∞—Ç: –∫—Ä–∞—Ç–∫–æ–µ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ""",
            
            "en": f"""Create a summary of the text no longer than {self.max_summary_length} characters.
            Preserve key information and important details.
            Use a neutral tone.
            Format: summary"""
        }
        
        return prompts.get(language, prompts["ru"]) 