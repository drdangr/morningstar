"""
Unified Celery App –¥–ª—è AI Services –≤ Docker –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–µ
"""

import os
from celery import Celery
from celery.signals import worker_ready, worker_shutdown
import redis
import time
import logging

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è Redis –∏ Backend
REDIS_URL = os.getenv('CELERY_BROKER_URL', 'redis://redis:6379/0')
RESULT_BACKEND = os.getenv('CELERY_RESULT_BACKEND', 'redis://redis:6379/0')
# Backend URL –¥–ª—è AI Tasks (–∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –≤ tasks.py)
# BACKEND_INTERNAL_URL –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –≤ tasks.py –∫–∞–∫ BACKEND_URL

# –°–æ–∑–¥–∞–Ω–∏–µ Celery app
app = Celery('ai_services')

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è Celery
app.conf.update(
    broker_url=REDIS_URL,
    result_backend=RESULT_BACKEND,
    
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –∑–∞–¥–∞—á
    task_serializer='json',
    accept_content=['json'],
    result_serializer='json',
    timezone='UTC',
    enable_utc=True,
    
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ worker
    worker_prefetch_multiplier=1,
    task_acks_late=True,
    worker_max_tasks_per_child=1000,
    
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    result_expires=3600,  # 1 —á–∞—Å
    
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –æ—á–µ—Ä–µ–¥–µ–π - –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ –∏–º–µ–Ω–∞ –∑–∞–¥–∞—á
    task_routes={
        'tasks.categorize_post': {'queue': 'categorization'},
        'tasks.summarize_posts': {'queue': 'summarization'},
        'tasks.process_digest': {'queue': 'processing'},
        'tasks.test_openai_connection': {'queue': 'testing'},
        'tasks.trigger_ai_processing': {'queue': 'orchestration'},
        'tasks.process_bot_digest': {'queue': 'processing'},
        'tasks.check_for_new_posts': {'queue': 'monitoring'},  # –ù–æ–≤–∞—è –æ—á–µ—Ä–µ–¥—å –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞
    },
    
    # Celery Beat –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏—Ö –∑–∞–¥–∞—á
    beat_schedule={
        'auto-check-new-posts': {
            'task': 'tasks.check_for_new_posts',
            'schedule': 30.0,  # –ö–∞–∂–¥—ã–µ 30 —Å–µ–∫—É–Ω–¥
            'options': {
                'queue': 'monitoring',
                'priority': 5,  # –ù–∏–∑–∫–∏–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç, –Ω–µ –º–µ—à–∞–µ—Ç –æ—Å–Ω–æ–≤–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–µ
            }
        },
    },
    beat_scheduler='celery.beat:PersistentScheduler',  # –°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ –≤ —Ñ–∞–π–ª
    
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏
    worker_disable_rate_limits=True,
    task_ignore_result=False,
    
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è
    broker_connection_retry_on_startup=True,
    broker_connection_retry=True,
    broker_connection_max_retries=10,
    
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞
    worker_send_task_events=True,
    task_send_sent_event=True,
)

def wait_for_redis():
    """–û–∂–∏–¥–∞–Ω–∏–µ –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏ Redis"""
    max_retries = 30
    retry_count = 0
    
    while retry_count < max_retries:
        try:
            r = redis.from_url(REDIS_URL)
            r.ping()
            logger.info("‚úÖ Redis connection established")
            return True
        except Exception as e:
            retry_count += 1
            logger.warning(f"‚è≥ Waiting for Redis... ({retry_count}/{max_retries}): {e}")
            time.sleep(2)
    
    logger.error("‚ùå Failed to connect to Redis after maximum retries")
    return False

@worker_ready.connect
def worker_ready_handler(sender=None, **kwargs):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏ worker"""
    logger.info("üöÄ AI Services Celery Worker is ready!")
    logger.info(f"Worker: {sender}")
    logger.info(f"Broker: {REDIS_URL}")
    logger.info(f"Backend: {RESULT_BACKEND}")

@worker_shutdown.connect
def worker_shutdown_handler(sender=None, **kwargs):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –≤—ã–∫–ª—é—á–µ–Ω–∏—è worker"""
    logger.info("üîÑ AI Services Celery Worker is shutting down...")

# –ò–º–ø–æ—Ä—Ç –∑–∞–¥–∞—á - –∏—Å–ø–æ–ª—å–∑—É–µ–º –ª–æ–∫–∞–ª—å–Ω—ã–µ –∏–º–ø–æ—Ä—Ç—ã –±–µ–∑ –ø—Ä–µ—Ñ–∏–∫—Å–∞ ai_services
from tasks import (
    ping_task,
    test_task,
    categorize_post,
    summarize_posts,
    process_digest,
    test_openai_connection,
    categorize_batch,
    summarize_batch
)

# –†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è –∑–∞–¥–∞—á - –∏—Å–ø–æ–ª—å–∑—É–µ–º –ª–æ–∫–∞–ª—å–Ω—ã–µ –º–æ–¥—É–ª–∏
app.autodiscover_tasks(['tasks'])

if __name__ == '__main__':
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ Redis
    if wait_for_redis():
        logger.info("Starting Celery worker...")
        app.start()
    else:
        logger.error("Failed to start: Redis not available")
        exit(1) 