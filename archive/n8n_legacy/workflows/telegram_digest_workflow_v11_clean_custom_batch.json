{
  "name": "Telegram Digest Workflow v11 - Clean Custom Batching",
  "nodes": [
    {
      "parameters": {
        "httpMethod": "POST",
        "path": "telegram-posts",
        "options": {}
      },
      "name": "Webhook - Receive Posts",
      "type": "n8n-nodes-base.webhook",
      "typeVersion": 1,
      "position": [
        -1280,
        -200
      ],
      "id": "2a5a49e5-e470-4c08-91f5-49f6a6005318",
      "webhookId": "telegram-posts-webhook"
    },
    {
      "parameters": {
        "functionCode": "// –ü–æ–ª—É—á–µ–Ω–∏–µ –∏ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –æ—Ç userbot —Å –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ–º webhook —Å—Ç—Ä—É–∫—Ç—É—Ä—ã\nconst rawData = $json;\nconsole.log('üì• Raw webhook data received:', JSON.stringify(rawData, null, 2));\n\n// –ò—Å–ø—Ä–∞–≤–ª—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –¥–∞–Ω–Ω—ã—Ö webhook (body vs direct)\nconst data = rawData.body || rawData;\nconsole.log('üìä Processing data structure...');\n\nif (!data) {\n    console.log('‚ùå No data found in webhook');\n    return { error: 'No data received', timestamp: new Date().toISOString() };\n}\n\nconst posts = data.posts || [];\nconst channelsMetadata = data.channels_metadata || {};\nconst collectionStats = data.collection_stats || {};\n\nconsole.log(`üìà Received: ${posts.length} posts from ${Object.keys(channelsMetadata).length} channels`);\nconsole.log('üìã Collection stats:', collectionStats);\n\nif (posts.length === 0) {\n    console.log('‚ö†Ô∏è No posts to process');\n    return {\n        posts: [],\n        channels_metadata: channelsMetadata,\n        collection_stats: collectionStats,\n        timestamp: new Date().toISOString(),\n        has_posts: false\n    };\n}\n\nconsole.log('‚úÖ Posts processed successfully');\nreturn {\n    posts: posts,\n    channels_metadata: channelsMetadata,\n    collection_stats: collectionStats,\n    timestamp: new Date().toISOString(),\n    has_posts: true\n};"
      },
      "name": "Process & Log Data",
      "type": "n8n-nodes-base.function",
      "typeVersion": 1,
      "position": [
        -1060,
        -200
      ],
      "id": "35cc1160-05b7-4114-a6ff-676a6c45ce92"
    },
    {
      "parameters": {
        "conditions": {
          "boolean": [
            {
              "value1": "={{ $json.has_posts }}",
              "value2": true
            }
          ]
        }
      },
      "name": "Has Posts?",
      "type": "n8n-nodes-base.if",
      "typeVersion": 1,
      "position": [
        -840,
        -200
      ],
      "id": "153c21da-04a1-4215-b929-a483e756438f"
    },
    {
      "parameters": {
        "functionCode": "// –ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –ø–æ—Å—Ç–æ–≤ –ø–æ –∫–∞–Ω–∞–ª–∞–º —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö\nconst data = $json;\nconst posts = data.posts || [];\nconst channelsMetadata = data.channels_metadata || {};\n\nconsole.log('üìä Grouping posts by channels...');\nconsole.log('üìã Available channels metadata:', Object.keys(channelsMetadata));\n\nconst grouped = {};\n\nposts.forEach(post => {\n    const key = post.channel_username || `channel_${post.channel_id}`;\n    \n    if (!grouped[key]) {\n        grouped[key] = {\n            channel_id: post.channel_id,\n            channel_username: post.channel_username,\n            channel_title: post.channel_title,\n            posts: [],\n            categories: channelsMetadata[post.channel_username]?.categories || []\n        };\n    }\n    \n    grouped[key].posts.push(post);\n});\n\nconst result = {\n    timestamp: data.timestamp,\n    stats: data.collection_stats,\n    grouped_posts: grouped,\n    channels_metadata: channelsMetadata\n};\n\nconsole.log(`üìà Grouped into ${Object.keys(grouped).length} channels`);\nObject.keys(grouped).forEach(key => {\n    const channel = grouped[key];\n    console.log(`  üì∫ ${channel.channel_title}: ${channel.posts.length} posts, ${channel.categories.length} categories`);\n});\n\nreturn result;"
      },
      "name": "Group by Channels",
      "type": "n8n-nodes-base.function",
      "typeVersion": 1,
      "position": [
        -620,
        -200
      ],
      "id": "a29788cc-d733-42b5-a185-73c29f873ebc"
    },
    {
      "parameters": {
        "functionCode": "// –£–õ–£–ß–®–ï–ù–û v7.2: –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è AI —Å–æ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è–º–∏\nconsole.log('ü§ñ Preparing data for OpenAI with STRUCTURED instructions v7.2...');\n\nconst groupedPostsData = $json;\nconst groupedPosts = groupedPostsData.grouped_posts || {};\nconst channelsMetadata = groupedPostsData.channels_metadata || {};\n\nconsole.log(`üìã Found grouped posts for ${Object.keys(groupedPosts).length} channels`);\nconsole.log('üìã Channels metadata available:', Object.keys(channelsMetadata));\n\n// –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï v7.1 + –£–õ–£–ß–®–ï–ù–ò–ï v7.2: –†–∞–∑–¥–µ–ª—è–µ–º –æ–±—ä–µ–∫—Ç—ã –¥–ª—è description –∏ ai_prompt\nconst channelCategoryMap = {};\nconst categoryDescriptions = {}; // –î–ª—è —Ç–µ–º –∞–Ω–∞–ª–∏–∑–∞ (description –ø–æ–ª–µ)\nconst categoryAIPrompts = {};     // –î–ª—è –∫–∞—Å—Ç–æ–º–Ω—ã—Ö –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–π (ai_prompt –ø–æ–ª–µ)\nlet allActiveCategories = new Set();\n\nObject.keys(groupedPosts).forEach(channelKey => {\n    const channelData = groupedPosts[channelKey];\n    const channelUsername = channelData.channel_username;\n    \n    console.log(`üìã –ö–∞–Ω–∞–ª: ${channelData.channel_title} (${channelUsername})`);\n    \n    // –ò—Å–ø–æ–ª—å–∑—É–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –ø—Ä—è–º–æ –∏–∑ grouped –¥–∞–Ω–Ω—ã—Ö –∏–ª–∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö\n    const categories = channelData.categories || channelsMetadata[channelUsername]?.categories || [];\n    const activeCategories = categories.filter(cat => cat.is_active);\n    \n    channelCategoryMap[channelUsername] = activeCategories;\n    \n    activeCategories.forEach(category => {\n        allActiveCategories.add(category.name);\n        \n        // –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï v7.1: –ø—Ä–∞–≤–∏–ª—å–Ω–æ —Ä–∞–∑–¥–µ–ª—è–µ–º –ø–æ–ª—è\n        if (category.description) {\n            categoryDescriptions[category.name] = category.description;\n        }\n        if (category.ai_prompt) {\n            categoryAIPrompts[category.name] = category.ai_prompt;\n        }\n        \n        console.log(`  üè∑Ô∏è –ê–∫—Ç–∏–≤–Ω–∞—è –∫–∞—Ç–µ–≥–æ—Ä–∏—è: ${category.name}`);\n        console.log(`    üìù Description: ${category.description?.substring(0, 50)}...`);\n        console.log(`    ü§ñ AI Prompt: ${category.ai_prompt?.substring(0, 50)}...`);\n    });\n    \n    if (activeCategories.length === 0) {\n        console.log(`  ‚ö†Ô∏è –ù–µ—Ç –∞–∫—Ç–∏–≤–Ω—ã—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏–π –¥–ª—è ${channelUsername}`);\n    }\n});\n\n// –§–æ—Ä–º–∏—Ä—É–µ–º —Å–ø–∏—Å–æ–∫ –∫–∞—Ç–µ–≥–æ—Ä–∏–π –¥–ª—è OpenAI\nconst categories = Array.from(allActiveCategories);\n\nconsole.log(`‚úÖ STRUCTURED v7.2: –ù–∞–π–¥–µ–Ω–æ ${categories.length} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∞–∫—Ç–∏–≤–Ω—ã—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏–π:`, categories);\nconsole.log('üîó –°–≤—è–∑–∏ –∫–∞–Ω–∞–ª–æ–≤ —Å –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º–∏:');\nObject.keys(channelCategoryMap).forEach(channel => {\n    const cats = channelCategoryMap[channel].map(c => c.name).join(', ');\n    console.log(`  ${channel} ‚Üí [${cats}]`);\n});\n\n// –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –ø–æ—Å—Ç—ã –¥–ª—è AI –∞–Ω–∞–ª–∏–∑–∞\nconst postsForAI = [];\n\nObject.keys(groupedPosts).forEach(channelKey => {\n    const channelData = groupedPosts[channelKey];\n    \n    channelData.posts.forEach(post => {\n        if (post.text && post.text.length > 50) {\n            postsForAI.push({\n                id: post.id,\n                text: post.text.substring(0, 1000),\n                channel: channelData.channel_title,\n                channel_username: channelData.channel_username,\n                views: post.views || 0,\n                date: post.date,\n                url: post.url,\n                channel_categories: channelCategoryMap[channelData.channel_username]?.map(c => c.name) || []\n            });\n        }\n    });\n});\n\nconsole.log(`üìù Prepared ${postsForAI.length} posts for AI analysis`);\n\n// –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï v7.1: –§–æ—Ä–º–∏—Ä—É–µ–º –æ–ø–∏—Å–∞–Ω–∏–µ —Ç–µ–º –∏–∑ –ø–æ–ª—è description (–≤–º–µ—Å—Ç–æ ai_prompt)\nconst topicsDescription = categories.map(cat => {\n    const description = categoryDescriptions[cat] || cat;\n    return `${cat} (${description})`;\n}).join(', ');\n\n// –£–õ–£–ß–®–ï–ù–ò–ï v7.2: –§–æ—Ä–º–∏—Ä—É–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∫–∞—Å—Ç–æ–º–Ω—ã–µ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏\nconst customInstructions = categories.map(cat => {\n    const description = categoryDescriptions[cat] || cat;\n    const aiPrompt = categoryAIPrompts[cat];\n    if (aiPrompt) {\n        return `–¥–ª—è –ø–æ—Å—Ç–æ–≤ –Ω–∞ —Ç–µ–º—É '${cat} (${description})' —É—á—Ç–∏ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏: ${aiPrompt}`;\n    }\n    return null;\n}).filter(instruction => instruction).join(', ');\n\n// –£–ª—É—á—à–µ–Ω–Ω—ã–π –ø—Ä–æ–º–ø—Ç —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ–º –ø–æ–ª–µ–π\nlet dynamicPrompt = `–û—Ç—Ñ–∏–ª—å—Ç—Ä—É–π –ø–æ—Å—Ç—ã –ø–æ —Ç–µ–º–∞–º: ${topicsDescription}.\\n\\n–ü—Ä–∞–≤–∏–ª–æ: summary = \\\"NULL\\\" –µ—Å–ª–∏ —Ç–µ–∫—Å—Ç –ø–æ—Å—Ç–∞ –ù–ï –∏–º–µ–µ—Ç –æ—Ç–Ω–æ—à–µ–Ω–∏—è –ù–ò –ö –û–î–ù–û–ô –∏–∑ –ø–µ—Ä–µ—á–∏—Å–ª–µ–Ω–Ω—ã—Ö —Ç–µ–º.\\n\\n–î–ª—è –∫–∞–∂–¥–æ–≥–æ –ø–æ—Å—Ç–∞:\\n\\n–ï–°–õ–ò –ø–æ—Å—Ç –∏–º–µ–µ—Ç –æ—Ç–Ω–æ—à–µ–Ω–∏–µ –∫ —Ç–µ–º–µ - –¥–∞–π –∫—Ä–∞—Ç–∫–æ–µ —Ä–µ–∑—é–º–µ + –º–µ—Ç—Ä–∏–∫–∏ 1-10.\\n–ï–°–õ–ò –ø–æ—Å—Ç –ù–ï –∏–º–µ–µ—Ç –æ—Ç–Ω–æ—à–µ–Ω–∏—è –∫ —Ç–µ–º–∞–º - –Ω–∞–ø–∏—à–∏ \\\"NULL\\\" + –º–µ—Ç—Ä–∏–∫–∏ 0.\\n\\n–í–æ–∑–≤—Ä–∞—â–∞–π JSON:\\n{\\\"results\\\": [{\\\"id\\\": \\\"post_id\\\", \\\"summary\\\": \\\"—Ä–µ–∑—é–º–µ –∏–ª–∏ NULL\\\", \\\"importance\\\": 8, \\\"urgency\\\": 6, \\\"significance\\\": 7, \\\"category\\\": \\\"–¢–æ—á–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ —Ç–µ–º—ã\\\"}]}\\n\\n–í–ê–ñ–ù–û:\\n- –ü–æ–ª–µ \\\"category\\\" –¥–æ–ª–∂–Ω–æ —Å–æ–¥–µ—Ä–∂–∞—Ç—å –¢–û–ß–ù–û–ï –Ω–∞–∑–≤–∞–Ω–∏–µ —Ç–µ–º—ã, –ø–æ –∫–æ—Ç–æ—Ä–æ–π –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω –ø–æ—Å—Ç: ${categories.join(', ')}\\n- –í—ã–±–∏—Ä–∞–π –ù–ê–ò–ë–û–õ–ï–ï –ü–û–î–•–û–î–Ø–©–£–Æ —Ç–µ–º—É –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ø–æ—Å—Ç–∞\\n- –î–ª—è –Ω–µ—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –ø–æ—Å—Ç–æ–≤: category = \\\"NULL\\\"\\n\\n–ê–Ω–∞–ª–∏–∑–∏—Ä—É–π –ø–æ –°–ú–´–°–õ–£, –∞ –Ω–µ —Ç–æ–ª—å–∫–æ –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º. –£—á–∏—Ç—ã–≤–∞–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏ —Å–µ–º–∞–Ω—Ç–∏–∫—É.`;\n\n// –£–õ–£–ß–®–ï–ù–ò–ï v7.2: –î–æ–±–∞–≤–ª—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∫–∞—Å—Ç–æ–º–Ω—ã–µ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏\nif (customInstructions) {\n    dynamicPrompt += `\\n\\n–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏: ${customInstructions}`;\n    console.log('‚úÖ Added STRUCTURED custom AI instructions from ai_prompt fields');\n}\n\nconsole.log('üîÆ Generated STRUCTURED prompt v7.2 with topic-specific instructions');\nconsole.log('üìä Categories for analysis (from description):', categories);\nconsole.log('üìä Structured instructions (from ai_prompt):', Object.keys(categoryAIPrompts).length, 'found');\nconsole.log('üéØ Topics description:', topicsDescription);\nif (customInstructions) {\n    console.log('ü§ñ Structured instructions:', customInstructions.substring(0, 200) + '...');\n}\n\n// FALLBACK —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –≤–æ–æ–±—â–µ –Ω–µ—Ç –∫–∞—Ç–µ–≥–æ—Ä–∏–π\nif (categories.length === 0) {\n    console.log('‚ùå –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê: –ù–µ—Ç –∞–∫—Ç–∏–≤–Ω—ã—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏–π, –∏—Å–ø–æ–ª—å–∑—É–µ–º fallback');\n    const fallbackPrompt = `–ê–Ω–∞–ª–∏–∑–∏—Ä—É–π –ø–æ—Å—Ç—ã –∏ –æ–ø—Ä–µ–¥–µ–ª—è–π –∏—Ö —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å –æ–±—â–∏–º –Ω–æ–≤–æ—Å—Ç–Ω—ã–º —Ç–µ–º–∞–º. –î–ª—è —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –ø–æ—Å—Ç–æ–≤ –¥–∞–≤–∞–π –∫—Ä–∞—Ç–∫–æ–µ —Ä–µ–∑—é–º–µ –∏ –º–µ—Ç—Ä–∏–∫–∏ –≤–∞–∂–Ω–æ—Å—Ç–∏/—Å—Ä–æ—á–Ω–æ—Å—Ç–∏/–∑–Ω–∞—á–∏–º–æ—Å—Ç–∏, –¥–ª—è –Ω–µ—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö - \\\"NULL\\\".`;\n    \n    return {\n        timestamp: groupedPostsData.timestamp,\n        stats: groupedPostsData.stats,\n        grouped_posts: groupedPosts,\n        posts_for_ai: postsForAI,\n        total_posts_for_ai: postsForAI.length,\n        dynamic_prompt: fallbackPrompt,\n        categories: ['–û–±—â–∏–µ –Ω–æ–≤–æ—Å—Ç–∏'],\n        channel_category_map: {},\n        error: 'No active categories found',\n        version: 'v7.2_fallback'\n    };\n}\n\nreturn {\n    timestamp: groupedPostsData.timestamp,\n    stats: groupedPostsData.stats,\n    grouped_posts: groupedPosts,\n    posts_for_ai: postsForAI,\n    total_posts_for_ai: postsForAI.length,\n    dynamic_prompt: dynamicPrompt,\n    categories: categories,\n    channel_category_map: channelCategoryMap,\n    category_descriptions: categoryDescriptions,\n    category_ai_prompts: categoryAIPrompts,\n    topics_description: topicsDescription,\n    custom_instructions: customInstructions,\n    binary_relevance: true,\n    with_metrics: true,\n    version: 'v7.3_individual_post_categorization'\n};"
      },
      "name": "Prepare for AI",
      "type": "n8n-nodes-base.function",
      "typeVersion": 1,
      "position": [
        -380,
        -200
      ],
      "id": "3e1e3620-3d5b-418b-abbd-49636d756410"
    },
    {
      "parameters": {
        "jsCode": "// –ö–ê–°–¢–û–ú–ù–´–ô –ë–ê–¢–ß–ò–ù–ì v11 - —Ä–∞–∑–±–∏–≤–∞–µ–º –ø–æ—Å—Ç—ã –Ω–∞ –ø–æ—Ä—Ü–∏–∏ –ø–æ 30\nconsole.log('üîÑ CUSTOM BATCH SPLITTER v11: Starting posts processing...');\n\nconst inputData = $json;\nconst postsForAI = inputData.posts_for_ai || [];\nconst batchSize = 30;\n\nconsole.log(`üìä Total posts to process: ${postsForAI.length}`);\nconsole.log(`üî¢ Batch size: ${batchSize}`);\n\nif (postsForAI.length === 0) {\n    console.log('‚ö†Ô∏è No posts to process');\n    return {\n        ...inputData,\n        batching_mode: 'none',\n        batch_count: 0,\n        current_batch: 1,\n        posts_for_ai: [],\n        original_posts_count: 0\n    };\n}\n\n// –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ –±–∞—Ç—á–∏\nconst batches = [];\nfor (let i = 0; i < postsForAI.length; i += batchSize) {\n    batches.push(postsForAI.slice(i, i + batchSize));\n}\n\nconsole.log(`üì¶ Created ${batches.length} batches`);\nbatches.forEach((batch, index) => {\n    console.log(`  Batch ${index + 1}: ${batch.length} posts`);\n});\n\n// –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –≥–ª–æ–±–∞–ª—å–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤\nif (!$execution.customData) {\n    $execution.customData = {};\n}\n$execution.customData.allAIResults = [];\n$execution.customData.batchesTotal = batches.length;\n$execution.customData.batchesProcessed = 0;\n$execution.customData.originalInputData = inputData;\n\n// –í–æ–∑–≤—Ä–∞—â–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –ø–µ—Ä–≤–æ–≥–æ –±–∞—Ç—á–∞\nreturn {\n    ...inputData,\n    batching_mode: 'custom',\n    batch_count: batches.length,\n    current_batch: 1,\n    posts_for_ai: batches[0], // –ü–µ—Ä–≤—ã–π –±–∞—Ç—á\n    remaining_batches: batches.slice(1), // –û—Å—Ç–∞–ª—å–Ω—ã–µ –±–∞—Ç—á–∏ –¥–ª—è —Ü–∏–∫–ª–∞\n    original_posts_count: postsForAI.length,\n    batching_version: 'v11_clean'\n};"
      },
      "name": "Custom Batch Splitter",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -360,
        -200
      ],
      "id": "custom-batch-splitter-v11"
    },
    {
      "parameters": {
        "modelId": {
          "__rl": true,
          "value": "gpt-4o",
          "mode": "list",
          "cachedResultName": "GPT-4O"
        },
        "messages": {
          "values": [
            {
              "content": "={{ $json.dynamic_prompt }}"
            },
            {
              "content": "=–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —ç—Ç–∏ –ø–æ—Å—Ç—ã:\\n\\n{{ JSON.stringify($json.posts_for_ai) }}"
            }
          ]
        },
        "jsonOutput": true,
        "options": {
          "maxTokens": 2000,
          "temperature": 0.3
        }
      },
      "name": "OpenAI API",
      "type": "@n8n/n8n-nodes-langchain.openAi",
      "typeVersion": 1,
      "position": [
        -160,
        -200
      ],
      "id": "d861ef0a-b2fb-4554-ac56-bfc05392d7fc",
      "credentials": {
        "openAiApi": {
          "id": "RinkWxXeXs9tiXAB",
          "name": "OpenAi account"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "// –ö–ê–°–¢–û–ú–ù–´–ô –ë–ê–¢–ß–ò–ù–ì v11 - —Å–æ–±–∏—Ä–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ—Ç –≤—Å–µ—Ö –±–∞—Ç—á–µ–π\nconsole.log('üîó CUSTOM BATCH COLLECTOR v11: Processing AI result...');\n\nconst currentAIResult = $json;\nconst splitterData = $('Custom Batch Splitter').first()?.json;\n\nconsole.log('üìù Current AI result:', JSON.stringify(currentAIResult, null, 2));\nconsole.log('üì¶ Splitter data:', {\n    batch_count: splitterData?.batch_count,\n    current_batch: splitterData?.current_batch,\n    batching_mode: splitterData?.batching_mode\n});\n\n// –ï—Å–ª–∏ –±–∞—Ç—á–∏–Ω–≥ –æ—Ç–∫–ª—é—á–µ–Ω (–Ω–µ—Ç –ø–æ—Å—Ç–æ–≤), –ø—Ä–æ—Å—Ç–æ –ø–µ—Ä–µ–¥–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç\nif (splitterData?.batching_mode === 'none') {\n    console.log('‚ö†Ô∏è No batching mode - passing through');\n    return currentAIResult;\n}\n\n// –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–µ–∫—É—â–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ –≥–ª–æ–±–∞–ª—å–Ω–æ–º —Ö—Ä–∞–Ω–∏–ª–∏—â–µ\nif (!$execution.customData) {\n    $execution.customData = {};\n}\nif (!$execution.customData.allAIResults) {\n    $execution.customData.allAIResults = [];\n}\nif (!$execution.customData.batchesProcessed) {\n    $execution.customData.batchesProcessed = 0;\n}\nif (!$execution.customData.batchesTotal) {\n    $execution.customData.batchesTotal = splitterData?.batch_count || 1;\n}\n\n$execution.customData.allAIResults.push(currentAIResult);\n$execution.customData.batchesProcessed += 1;\n\nconsole.log(`üìä Processed batch ${$execution.customData.batchesProcessed}/${$execution.customData.batchesTotal}`);\n\n// –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –µ—â–µ –±–∞—Ç—á–∏ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏\nconst remainingBatches = splitterData?.remaining_batches || [];\nconst hasMoreBatches = $execution.customData.batchesProcessed < $execution.customData.batchesTotal;\n\nif (hasMoreBatches && remainingBatches.length > 0) {\n    console.log(`üîÑ Processing next batch: ${$execution.customData.batchesProcessed + 1}`);\n    \n    // –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è —Å–ª–µ–¥—É—é—â–µ–≥–æ –±–∞—Ç—á–∞\n    const nextBatchIndex = $execution.customData.batchesProcessed;\n    const nextBatch = remainingBatches[nextBatchIndex - 1]; // -1 –ø–æ—Ç–æ–º—É —á—Ç–æ –ø–µ—Ä–≤—ã–π –±–∞—Ç—á —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω\n    \n    // –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∏—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∏ –∑–∞–º–µ–Ω—è–µ–º posts_for_ai\n    const nextBatchData = {\n        ...$execution.customData.originalInputData,\n        batching_mode: 'custom',\n        batch_count: splitterData.batch_count,\n        current_batch: $execution.customData.batchesProcessed + 1,\n        posts_for_ai: nextBatch,\n        remaining_batches: remainingBatches,\n        original_posts_count: splitterData.original_posts_count,\n        batching_version: 'v11_clean'\n    };\n    \n    console.log(`üì§ Sending next batch with ${nextBatch.length} posts`);\n    \n    // –ü–µ—Ä–µ–Ω–∞–ø—Ä–∞–≤–ª—è–µ–º –Ω–∞ OpenAI –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å–ª–µ–¥—É—é—â–µ–≥–æ –±–∞—Ç—á–∞\n    console.log('üîÑ Redirecting to OpenAI for next batch processing');\n    \n    // –í–æ–∑–≤—Ä–∞—â–∞–µ–º –¥–∞–Ω–Ω—ã–µ –≤ —Ñ–æ—Ä–º–∞—Ç–µ, –∫–æ—Ç–æ—Ä—ã–π –æ–∂–∏–¥–∞–µ—Ç OpenAI\n    return {\n        ...nextBatchData,\n        _redirectToOpenAI: true\n    };\n}\n\n// –ï—Å–ª–∏ –≤—Å–µ –±–∞—Ç—á–∏ –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã, —Å–æ–±–∏—Ä–∞–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç\nif (!hasMoreBatches) {\n    console.log('‚úÖ All batches processed - collecting final result');\n    \n    // –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤—Å–µ AI —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã\n    const allResults = $execution.customData.allAIResults;\n    console.log(`üîó Merging ${allResults.length} AI results`);\n    \n    // –°–æ–∑–¥–∞–µ–º –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç\n    // –í–ê–ñ–ù–û: –ù–ï –ú–ï–ù–Ø–ï–ú –°–¢–†–£–ö–¢–£–†–£ - —Ç–æ–ª—å–∫–æ –æ–±—ä–µ–¥–∏–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã AI\n    let combinedAIResponse;\n    \n    if (allResults.length === 1) {\n        // –¢–æ–ª—å–∫–æ –æ–¥–∏–Ω –±–∞—Ç—á - –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–∞–∫ –µ—Å—Ç—å\n        combinedAIResponse = allResults[0];\n    } else {\n        // –ù–µ—Å–∫–æ–ª—å–∫–æ –±–∞—Ç—á–µ–π - –æ–±—ä–µ–¥–∏–Ω—è–µ–º results\n        const allAIResults = [];\n        \n        allResults.forEach((result, index) => {\n            console.log(`üìù Processing result ${index + 1}:`, typeof result);\n            \n            if (result?.message?.content?.results) {\n                allAIResults.push(...result.message.content.results);\n            } else if (result?.message?.content && typeof result.message.content === 'string') {\n                try {\n                    const parsed = JSON.parse(result.message.content);\n                    if (parsed.results) {\n                        allAIResults.push(...parsed.results);\n                    }\n                } catch (e) {\n                    console.log(`‚ö†Ô∏è Failed to parse batch ${index + 1} content:`, e.message);\n                }\n            }\n        });\n        \n        console.log(`üîó Combined ${allAIResults.length} AI analysis items`);\n        \n        // –§–æ—Ä–º–∏—Ä—É–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É –≤ —Ç–æ–º –∂–µ —Ñ–æ—Ä–º–∞—Ç–µ —á—Ç–æ OpenAI\n        combinedAIResponse = {\n            message: {\n                content: {\n                    results: allAIResults\n                }\n            },\n            custom_batching_applied: true,\n            batches_processed: allResults.length,\n            total_ai_items: allAIResults.length\n        };\n    }\n    \n    console.log('üéâ Final combined AI response ready:', {\n        batches: allResults.length,\n        total_items: combinedAIResponse?.message?.content?.results?.length || 0\n    });\n    \n    return combinedAIResponse;\n}\n\n// –ü—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ (–Ω–µ –¥–æ–ª–∂–Ω–æ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç—å –≤ —Ç–µ–∫—É—â–µ–π —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏)\nconsole.log('‚ö†Ô∏è Intermediate state - this should not happen');\nreturn currentAIResult;"
      },
      "name": "Custom Batch Collector",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -60,
        -200
      ],
      "id": "custom-batch-collector-v11"
    },
    {
      "parameters": {
        "functionCode": "// –§–∏–Ω–∞–ª—å–Ω–∞—è –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–π–¥–∂–µ—Å—Ç–∞ —Å Binary Relevance + Metrics –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π\nconst processedChannels = $json.processed_channels || {};\n\nconsole.log('üìÑ Preparing final digest with Binary Relevance + Metrics...');\n\nconst digest = {\n  id: `digest_${Date.now()}`,\n  created_at: $json.timestamp,\n  processed_at: $json.processed_at,\n  channels: [],\n  total_posts: 0,\n  binary_relevance_applied: true,\n  with_metrics: true,\n  summary: {\n    channels_processed: Object.keys(processedChannels).length,\n    original_posts: $json.stats?.total_posts || 0,\n    relevant_posts: $json.ai_analysis_stats?.relevant_posts || 0,\n    avg_importance: $json.ai_analysis_stats?.avg_importance || 0,\n    avg_urgency: $json.ai_analysis_stats?.avg_urgency || 0,\n    avg_significance: $json.ai_analysis_stats?.avg_significance || 0\n  }\n};\n\nObject.keys(processedChannels).forEach(channelKey => {\n  const channelData = processedChannels[channelKey];\n  \n  digest.channels.push({\n    title: channelData.channel_title,\n    username: channelData.channel_username,\n    categories: channelData.channel_categories || [],\n    posts_count: channelData.posts.length,\n    relevant_posts: channelData.relevant_posts || 0,\n    posts: channelData.posts.map(post => ({\n      title: (post.text || '').substring(0, 100) + '...',\n      url: post.url,\n      views: post.views,\n      date: post.date,\n      ai_importance: post.ai_importance,\n      ai_urgency: post.ai_urgency,\n      ai_significance: post.ai_significance,\n      summary: post.ai_summary,\n      // v7.3: –ò–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω–∞—è —Ç–µ–º–∞ –ø–æ—Å—Ç–∞ –æ—Ç AI\n      post_category: post.post_category,\n      ai_assigned_category: post.ai_assigned_category\n    }))\n  });\n  \n  digest.total_posts += channelData.posts.length;\n});\n\nconsole.log(`‚úÖ Digest ready with Binary Relevance + Metrics: ${digest.total_posts} posts from ${digest.channels.length} channels`);\nconsole.log(`üìä Relevant posts: ${digest.summary.relevant_posts}`);\nconsole.log(`üìà Avg metrics - Importance: ${digest.summary.avg_importance.toFixed(1)}, Urgency: ${digest.summary.avg_urgency.toFixed(1)}, Significance: ${digest.summary.avg_significance.toFixed(1)}`);\n\nreturn digest;"
      },
      "name": "Prepare Digest",
      "type": "n8n-nodes-base.function",
      "typeVersion": 1,
      "position": [
        340,
        -200
      ],
      "id": "607d7911-4fc4-4b35-bae9-736fa85a5b3b"
    },
    {
      "parameters": {
        "functionCode": "// –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –¥–∞–π–¥–∂–µ—Å—Ç–∞ –≤ Backend API\nconst digest = $json;\n\nconsole.log('üíæ Saving digest to Backend API...');\nconsole.log('Digest ID:', digest.id);\nconsole.log('Total posts:', digest.total_posts);\nconsole.log('Channels:', digest.channels.length);\nconsole.log('Binary Relevance applied:', digest.binary_relevance_applied);\nconsole.log('With Metrics:', digest.with_metrics);\nconsole.log('Relevant posts:', digest.summary.relevant_posts);\n\n// –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è Backend API\nconst backendPayload = {\n  digest_id: digest.id,\n  total_posts: digest.total_posts,\n  channels_processed: digest.summary.channels_processed,\n  original_posts: digest.summary.original_posts,\n  relevant_posts: digest.summary.relevant_posts,\n  avg_importance: digest.summary.avg_importance,\n  avg_urgency: digest.summary.avg_urgency,\n  avg_significance: digest.summary.avg_significance,\n  binary_relevance_applied: digest.binary_relevance_applied,\n  with_metrics: digest.with_metrics,\n  digest_data: JSON.stringify(digest), // –ü–æ–ª–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–∞–π–¥–∂–µ—Å—Ç–∞ –∫–∞–∫ JSON —Å—Ç—Ä–æ–∫–∞\n  processed_at: digest.processed_at\n};\n\nconsole.log('üì§ Payload for Backend API:', JSON.stringify(backendPayload, null, 2));\n\n// –í–æ–∑–≤—Ä–∞—â–∞–µ–º payload –¥–ª—è HTTP Request node\nreturn {\n  success: true,\n  digest_id: digest.id,\n  backend_payload: backendPayload,\n  message: `Binary Relevance + Metrics digest prepared for Backend API: ${digest.total_posts} posts, ${digest.summary.relevant_posts} relevant`,\n  timestamp: new Date().toISOString(),\n  metrics_stats: {\n    avg_importance: digest.summary.avg_importance,\n    avg_urgency: digest.summary.avg_urgency,\n    avg_significance: digest.summary.avg_significance,\n    channels_with_categories: digest.channels.filter(ch => ch.categories.length > 0).length\n  }\n};"
      },
      "name": "Prepare Backend Payload",
      "type": "n8n-nodes-base.function",
      "typeVersion": 1,
      "position": [
        520,
        -200
      ],
      "id": "43c2e287-aaca-4bf6-808c-9c10c3a7dd01"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "http://127.0.0.1:8000/api/digests",
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "Content-Type",
              "value": "application/json"
            }
          ]
        },
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={{ JSON.stringify($json.backend_payload) }}",
        "options": {}
      },
      "name": "Save to Backend API",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.1,
      "position": [
        740,
        -200
      ],
      "id": "d8b9607a-9596-4eba-b583-02bffb531839"
    },
    {
      "parameters": {
        "functionCode": "// –§–∏–Ω–∞–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤ Backend API\nconst apiResponse = $json;\nconst preparePayloadData = $('Prepare Backend Payload').all()[0]?.json;\n\nconsole.log('‚úÖ Backend API response:', JSON.stringify(apiResponse, null, 2));\n\nif (apiResponse.digest_id) {\n  console.log('üéâ Digest successfully saved to Backend API!');\n  console.log('üìä Digest ID:', apiResponse.digest_id);\n  console.log('üìà Total posts:', apiResponse.total_posts);\n  console.log('üìä Relevant posts:', apiResponse.relevant_posts);\n  \n  return {\n    success: true,\n    digest_id: apiResponse.digest_id,\n    backend_id: apiResponse.id,\n    message: `Digest saved to Backend API successfully!`,\n    timestamp: new Date().toISOString(),\n    api_response: apiResponse,\n    metrics_stats: preparePayloadData?.metrics_stats || {}\n  };\n} else {\n  console.log('‚ùå Failed to save digest to Backend API');\n  \n  return {\n    success: false,\n    error: 'Failed to save to Backend API',\n    api_response: apiResponse,\n    timestamp: new Date().toISOString()\n  };\n}"
      },
      "name": "Process API Response",
      "type": "n8n-nodes-base.function",
      "typeVersion": 1,
      "position": [
        960,
        -200
      ],
      "id": "9a7b7bfd-c62d-4f1e-903f-d7756580be14"
    },
    {
      "parameters": {
        "functionCode": "// –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å–ª—É—á–∞—è –∫–æ–≥–¥–∞ –Ω–µ—Ç –ø–æ—Å—Ç–æ–≤\nconsole.log('‚ö†Ô∏è No posts received from userbot');\n\nreturn {\n  success: false,\n  message: 'No posts to process',\n  timestamp: new Date().toISOString()\n};"
      },
      "name": "No Posts Handler",
      "type": "n8n-nodes-base.function",
      "typeVersion": 1,
      "position": [
        -840,
        100
      ],
      "id": "574ff489-12b3-4083-b01b-afcc7b07a157"
    },
    {
      "parameters": {
        "functionCode": "// –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –æ—Ç OpenAI —Å Binary Relevance + –ú–µ—Ç—Ä–∏–∫–∏ –ø–æ–¥—Ö–æ–¥–æ–º v6.0\nconsole.log('ü§ñ Processing OpenAI response with Binary Relevance + Metrics v6.0...');\n\ntry {\n    // –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –æ—Ç –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö —É–∑–ª–æ–≤\n    const prepareForAIData = $('Custom Batch Splitter').all()[0]?.json;\n    if (!prepareForAIData) {\n        throw new Error('Could not find data from Custom Batch Splitter node');\n    }\n    \n    const groupedPosts = prepareForAIData.grouped_posts || {};\n    const channelCategoryMap = prepareForAIData.channel_category_map || {};\n    const originalStats = prepareForAIData.stats || {};\n    const originalTimestamp = prepareForAIData.timestamp || '';\n    \n    console.log('‚úÖ Found data from Prepare for AI node');\n    console.log('üìä Channel-Category mapping:', Object.keys(channelCategoryMap));\n    \n    // –ò–∑–≤–ª–µ–∫–∞–µ–º AI –æ—Ç–≤–µ—Ç (—É–ª—É—á—à–µ–Ω–Ω–æ–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –ø–∞—Ä—Å–∏–Ω–≥)\n    let aiAnalysis = [];\n    \n    console.log('üîç RAW OpenAI response structure:', JSON.stringify($json, null, 2));\n    \n    if ($json.message?.content?.results) {\n        aiAnalysis = $json.message.content.results;\n        console.log('‚úÖ Found AI response in $json.message.content.results (direct format)', aiAnalysis.length, 'items');\n    } else if ($json[0]?.message?.content?.results) {\n        aiAnalysis = $json[0].message.content.results;\n        console.log('‚úÖ Found AI response in $json[0].message.content.results (array format)', aiAnalysis.length, 'items');\n    } else if ($json[0]?.message?.content?.posts) {\n        aiAnalysis = $json[0].message.content.posts;\n        console.log('‚úÖ Found AI response in $json[0].message.content.posts (array format)', aiAnalysis.length, 'items');\n    } else if ($json[0]?.message?.content && typeof $json[0].message.content === 'object') {\n        // –í–æ–∑–º–æ–∂–Ω–æ content —ç—Ç–æ –æ–±—ä–µ–∫—Ç –Ω–∞–ø—Ä—è–º—É—é, –∞ –Ω–µ —Å—Ç—Ä–æ–∫–∞\n        if ($json[0].message.content.results) {\n            aiAnalysis = $json[0].message.content.results;\n            console.log('‚úÖ Found AI response in $json[0].message.content.results (direct object)', aiAnalysis.length, 'items');\n        } else {\n            console.log('‚ö†Ô∏è Content is object but no results field found');\n        }\n    } else if ($json.message?.content && typeof $json.message.content === 'string') {\n        try {\n            const parsed = JSON.parse($json.message.content);\n            aiAnalysis = parsed.results || parsed;\n            console.log('‚úÖ Found AI response in message.content (string format)', aiAnalysis.length, 'items');\n        } catch (error) {\n            console.log('‚ö†Ô∏è Failed to parse message.content as JSON:', error.message);\n        }\n    } else if (Array.isArray($json)) {\n        aiAnalysis = $json;\n        console.log('‚úÖ Found AI response as direct array', aiAnalysis.length, 'items');\n    } else {\n        console.log('‚ùå Could not find AI response in expected fields');\n        console.log('üîç Available $json structure keys:', Object.keys($json));\n        if ($json[0]) {\n            console.log('üîç $json[0] structure keys:', Object.keys($json[0]));\n            if ($json[0].message) {\n                console.log('üîç $json[0].message structure keys:', Object.keys($json[0].message));\n            }\n        }\n    }\n    \n    console.log(`üìù AI Analysis extracted: ${aiAnalysis.length} items`);\n    \n    // –ü—Ä–∏–º–µ–Ω—è–µ–º AI –∞–Ω–∞–ª–∏–∑ –∫ –ø–æ—Å—Ç–∞–º —Å Binary Relevance –ø–æ–¥—Ö–æ–¥–æ–º\n    const processedChannels = {};\n    \n    Object.keys(groupedPosts).forEach(channelKey => {\n        const channelData = groupedPosts[channelKey];\n        const channelCategories = channelCategoryMap[channelData.channel_username] || [];\n        \n        console.log(`üîÑ Processing channel: ${channelData.channel_title}`);\n        console.log(`  üè∑Ô∏è Channel categories: ${channelCategories.map(c => c.name).join(', ')}`);\n        \n        const processedPosts = channelData.posts.map(post => {\n            // –ò—â–µ–º AI –∞–Ω–∞–ª–∏–∑ –¥–ª—è —ç—Ç–æ–≥–æ –ø–æ—Å—Ç–∞\n            const analysis = aiAnalysis.find(item => \n                item.id == post.id || \n                (item.text && post.text && item.text.includes(post.text.substring(0, 50)))\n            );\n            \n            // Binary Relevance v6.0: –ø—Ä–æ—Å—Ç–æ –ø—Ä–æ–≤–µ—Ä—è–µ–º summary !== \\\"NULL\\\"\n            const isRelevant = analysis && analysis.summary && analysis.summary !== 'NULL';\n            \n            const result = {\n                ...post,\n                ai_summary: analysis?.summary || post.text?.substring(0, 150) + '...',\n                ai_importance: analysis?.importance || 0,\n                ai_urgency: analysis?.urgency || 0,\n                ai_significance: analysis?.significance || 0,\n                processed_by_ai: !!analysis,\n                channel_categories: channelCategories.map(c => c.name),\n                // v7.3: –ò–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω–∞—è –∫–∞—Ç–µ–≥–æ—Ä–∏—è –ø–æ—Å—Ç–∞ –æ—Ç AI\n                post_category: analysis?.category || 'Unknown',\n                ai_assigned_category: analysis?.category || '',\n                // Binary Relevance: —Ä–µ–ª–µ–≤–∞–Ω—Ç–µ–Ω –µ—Å–ª–∏ summary –Ω–µ NULL\n                is_relevant: isRelevant,\n                parsing_method: 'individual_post_categorization_v7.3'\n            };\n            \n            console.log(`  üìù Post ${post.id}: relevant=${isRelevant}, importance=${result.ai_importance}, urgency=${result.ai_urgency}, significance=${result.ai_significance}`);\n            return result;\n        });\n        \n        // –§–∏–ª—å—Ç—Ä—É–µ–º —Ç–æ–ª—å–∫–æ –ø–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ (summary !== NULL)\n        const relevantPosts = processedPosts.filter(post => {\n            if (!post.is_relevant) {\n                console.log(`  ‚ö†Ô∏è –ü–æ—Å—Ç ${post.id} –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω: –Ω–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–µ–Ω (summary=NULL)`);\n                return false;\n            }\n            return true;\n        });\n        \n        // –£–º–Ω–∞—è —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ –º–µ—Ç—Ä–∏–∫–∞–º + views\n        relevantPosts.sort((a, b) => {\n            const scoreA = a.ai_importance * 3 + a.ai_urgency * 2 + a.ai_significance * 2 + Math.log(a.views || 1);\n            const scoreB = b.ai_importance * 3 + b.ai_urgency * 2 + b.ai_significance * 2 + Math.log(b.views || 1);\n            return scoreB - scoreA;\n        });\n        \n        processedChannels[channelKey] = {\n            ...channelData,\n            posts: relevantPosts.slice(0, 8), // –¢–æ–ø 8\n            all_processed_posts: processedPosts.length,\n            relevant_posts: relevantPosts.length,\n            ai_processed: true,\n            channel_categories: channelCategories.map(c => c.name)\n        };\n        \n        console.log(`üìä ${channelData.channel_title}: ${processedPosts.length} total ‚Üí ${relevantPosts.length} relevant ‚Üí ${Math.min(8, relevantPosts.length)} final`);\n    });\n    \n    const result = {\n        timestamp: originalTimestamp || new Date().toISOString(),\n        processed_at: new Date().toISOString(),\n        stats: originalStats,\n        processed_channels: processedChannels,\n        total_channels: Object.keys(processedChannels).length,\n        ai_analysis_stats: {\n            total_analyzed: aiAnalysis.length,\n            avg_importance: aiAnalysis.reduce((sum, item) => sum + (item.importance || 0), 0) / Math.max(aiAnalysis.length, 1),\n            avg_urgency: aiAnalysis.reduce((sum, item) => sum + (item.urgency || 0), 0) / Math.max(aiAnalysis.length, 1),\n            avg_significance: aiAnalysis.reduce((sum, item) => sum + (item.significance || 0), 0) / Math.max(aiAnalysis.length, 1),\n            relevant_posts: Object.values(processedChannels).reduce((sum, ch) => sum + ch.relevant_posts, 0)\n        },\n        many_to_many_applied: true,\n        relevance_parsing_version: 'v7.3_individual_post_categorization'\n    };\n    \n    console.log('üîç FINAL RESULT with Binary Relevance + Metrics v6.0:', JSON.stringify(result, null, 2));\n    return result;\n    \n} catch (error) {\n    console.log('‚ùå Error in Process AI Results:', error.message);\n    return {\n        error: 'Failed to process AI results: ' + error.message,\n        timestamp: new Date().toISOString(),\n        processed_channels: {},\n        total_channels: 0\n    };\n}"
      },
      "name": "Process AI Results1",
      "type": "n8n-nodes-base.function",
      "typeVersion": 1,
      "position": [
        160,
        -200
      ],
      "id": "1480aa74-a595-4fca-900a-15bd5646772e"
    }
  ],
  "pinData": {},
  "connections": {
    "Webhook - Receive Posts": {
      "main": [
        [
          {
            "node": "Process & Log Data",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Process & Log Data": {
      "main": [
        [
          {
            "node": "Has Posts?",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Has Posts?": {
      "main": [
        [
          {
            "node": "Group by Channels",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "No Posts Handler",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Group by Channels": {
      "main": [
        [
          {
            "node": "Prepare for AI",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Prepare for AI": {
      "main": [
        [
          {
            "node": "Custom Batch Splitter",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Custom Batch Splitter": {
      "main": [
        [
          {
            "node": "OpenAI API",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "OpenAI API": {
      "main": [
        [
          {
            "node": "Custom Batch Collector",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Custom Batch Collector": {
      "main": [
        [
          {
            "node": "Process AI Results1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Process AI Results1": {
      "main": [
        [
          {
            "node": "Prepare Digest",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Prepare Digest": {
      "main": [
        [
          {
            "node": "Prepare Backend Payload",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Prepare Backend Payload": {
      "main": [
        [
          {
            "node": "Save to Backend API",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Save to Backend API": {
      "main": [
        [
          {
            "node": "Process API Response",
            "type": "main",
            "index": 0
          }
        ]
      ]
    }
  },
  "active": true,
  "settings": {
    "executionOrder": "v1"
  },
  "versionId": "c775ca16-7582-474d-beff-68a2400a24fb",
  "meta": {
    "instanceId": "883bf09e5b1ec169d367de4fbfec1bb4c59c9cdd2c1af7d7b7c29577e28e6ee0"
  },
  "id": "pXDfiV9LFke5isaP",
  "tags": []
}